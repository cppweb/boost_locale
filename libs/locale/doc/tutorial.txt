// vim: tabstop=4 expandtab shiftwidth=4 softtabstop=4 filetype=cpp.doxygen

/*!

\mainpage Boost.Locale

\htmlonly <p style="font-size:80%; text-align:center">(Under development for Boost)</p> \endhtmlonly

\section main_intro What is Boost.Locale?

Boost.Locale is a library that provides high quality localization facilities in a C++ way. It uses \c
std::locale facets to provide localization in transparent and C++-aware manner.

C++ offers a very good base for localization via the existing C++ locale facets: \c std::num_put,
\c std::ctype, \c std::collate etc. But these are very limited and sometimes buggy by design. Support
for localization varies between different operating systems, compilers, and standard libraries,
and there are frequently incompatibilities between them.

On the other hand, there is a great, well debugged, high quality, widely used ICU library that gives
all of the goodies. But it has a very dated API that mimics Java behavior, completely ignores the STL,
and provides a useful API only for UTF-16 encoded text, ignoring other popular Unicode encodings like
UTF-8 and UTF-32 and limited but still popular national character sets like Latin1.

Boost.Locale provides the natural glue between the C++ locales framework, iostreams, and the powerful
ICU library.

Boost.Locale provides non-ICU based localization support as well. It is based on
the operating system native API or on the standard C++ library support.
Sacrificing some less important features, Boost.Locale becomes less powerful but 
lighter and easier to deploy and use library.

\section main_intro_features Provided Features

- Correct case conversion, case folding and <a href="http://en.wikipedia.org/wiki/Unicode_equivalence">normalization</a>.
- <a href="http://en.wikipedia.org/wiki/Collation">Collation</a> (sorting), including support for 4 Unicode collation levels.
- Date, time, timezone and calendar manipulations, formatting and parsing, including transparent
support for calendars <a href="http://en.wikipedia.org/wiki/List_of_calendars">other than Gregorian</a>.
- Boundary analysis for characters, words, sentences and line-breaks.
- Number formatting, spelling and parsing.
- Monetary formatting and parsing.
- Powerful message formatting (string translation) including support for plural forms, using GNU catalogs.
- Character set conversion.
- Transparent support for 8-bit character sets like Latin1
- Support for \c char and \c wchar_t
- Experimental support for C++0x \c char16_t and \c char32_t strings and streams.

\section main_tutorial Tutorials

- \subpage std_locales
- \subpage using_boost_locale
    - \ref locale_gen
    - \ref collation
    - \ref conversions
    - \ref formatting_and_parsing
    - \ref messages_formatting
    - \ref charset_handling 
    - \ref boundary_analysys
    - \ref localized_text_formatting
    - \ref dates_times_timezones
    - \ref locale_information
    - \ref working_with_multiple_locales
- \subpage using_localization_backends
- \subpage recommendations_and_myths
- \subpage building_boost_locale
- \subpage appendix
    - \ref rationale
    - \ref default_encoding_under_windows
    - \ref running_examples_under_windows 
    - \ref glossary
    - \ref tested_compilers_and_paltforms 
    - \ref status_of_cpp0x_characters_support
    - \ref special_thanks
    - \ref copyright

\page std_locales Introduction to C++ Standard Library localization support

\section std_locales_basics Getting familiar with standard C++ Locales

The C++ standard library offers a simple and powerful way to provide locale-specific information. It is done via the \c 
std::locale class, the container that holds all the required information about a specific culture, such as number formatting
patterns, date and time formatting, currency, case conversion etc.

All this information is provided by facets, special classes derived from the \c std::locale::facet base class. Such facets are
packed into the \c std::locale class and allow you to provide arbitrary information about the locale. The \c std::locale class
keeps reference counters on installed facets and can be efficiently copied.

Each facet that was installed into the \c std::locale object can be fetched using the \c std::use_facet function. For example,
the \c std::ctype<Char> facet provides rules for case conversion, so you can convert a character to upper-case like this:

\code
std::ctype<char> const &ctype_facet = std::use_facet<std::ctype>(some_locale);
char upper_a = ctype_facet.toupper('a');
\endcode

A locale object can be imbued into an \c iostream so it would format information according to the locale:

\code
cout.imbue(std::locale("en_US.UTF-8"));
cout << 1345.45 << endl;
cout.imbue(std::locale("ru_RU.UTF-8"));
cout << 1345.45 << endl;
\endcode

Would display:

\verbatim
    1,345.45 1.345,45
\endverbatim

You can also create your own facets and install them into existing locale objects. For example:

\code
    class measure : public std::locale::facet {
    public:
        typedef enum { inches, ... } measure_type;
        measure(measure_type m,size_t refs=0) 
        double from_metric(double value) const;
        std::string name() const;
        ...
    };
\endcode
And now you can simply provide this information to a locale:

\code
    std::locale::global(std::locale(std::locale("en_US.UTF-8"),new measure(paper_size::inches)));
    /// Create default locale built from en_US locale and add paper size facet.
\endcode


Now you can print a distance according to the correct locale:

\code
    void print_distance(std::ostream &out,double value)
    {
        measure const &m = std::use_facet<measure>(out.getloc());
        // Fetch locale information from stream
        std::cout << m.from_metric(value) << " " << m.name();
    }
\endcode

This technique was adopted by the Boost.Locale library in order to provide powerful and correct localization. Instead of using
the very limited C++ standard library facets, it uses ICU under the hood to create its own much more powerful ones.

\section std_locales_common Common Critical Problems with the Standard Library

There are numerous issues in the standard library that prevent the use of its full power, and there are several
additional issues:

-   Setting the global locale has bad side effects.
    .
    Consider following code:
    .
    \code
        int main()
        {
            std::locale::global(std::locale("")); 
            // Set default locale as global
            std::ofstream csv("test.csv");
            csv << 1.1 << ","  << 1.3 << std::endl;
        }
    \endcode
    .
    What would be the content of \c test.csv ? It may be "1.1,1.3" or it may be "1,1,1,3" 
    rather than what you had expected.
    .
    More than that it affects even \c printf and libraries like \c boost::lexical_cast giving
    incorrect or unexpected formatting. In fact many third-party libraries are broken in such a
    situation.
    .
    Unlike the standard localization library, Boost.Locale never changes the basic number formatting,
    even when it uses \c std based localization backends, so by default, numbers are always
    formatted using C-style locale. Localized number formatting requires specific flags.
    .
-   Number formatting is broken on some locales.
    .
    Some locales use the non-breakable space u00A0 character for thousands separator, thus
    in \c ru_RU.UTF-8 locale number 1024 should be displayed as "1 024" where the space
    is a Unicode character with codepoint u00A0. Unfortunately many libraries don't handle
    this correctly, for example GCC and SunStudio display a "\xC2" character instead of
    the first character in the UTF-8 sequence "\xC2\xA0" that represents this code point, and 
    actually generate invalid UTF-8.
    .
-   Locale names are not standardized. For example, under MSVC you need to provide the name
    \c en-US or \c English_USA.1252 , when on POSIX platforms it would be \c en_US.UTF-8 
    or \c en_US.ISO-8859-1 
    .
    More than that, MSVC does not support UTF-8 locales at all.
    .
-   Many standard libraries provide only the C and POSIX locales, thus GCC supports localization
    only under Linux. On all other platforms, attempting to create locales other than "C" or
    "POSIX" would fail.

\page using_boost_locale Using Boost.Locale

In this section we'll talk mostly about the ICU backend, as it is both the default and the most powerful
localization backend provided by this library. In later sections we will note the features that are
supported by other localization backends.


- \subpage locale_gen
- \subpage collation
- \subpage conversions
- \subpage formatting_and_parsing
- \subpage messages_formatting
- \subpage charset_handling
- \subpage boundary_analysys
- \subpage localized_text_formatting
- \subpage dates_times_timezones
- \subpage locale_information
- \subpage working_with_multiple_locales 


\page locale_gen Locale Generation

Each locale is defined by a specific locale identifier, which contains a mandatory part (Language) and several optional parts
(Country, Variant, keywords and character encoding of \c std::string). Boost.Locale uses the POSIX naming convention for locales,
i.e. a locale is defined as <tt>language[_COUNTRY][.encoding][\@variant]</tt>, where lang is ISO-639 language name like "en" or "ru",
COUNTRY is the ISO-3166 country identifier like "US" or "DE", encoding is the eight-bit character encoding like \c UTF-8 or \c ISO-8859-1,
and variant is additional options for specializing the locale, like \c euro or \c calendar=hebrew.

Note that each locale should include the encoding in order to handle \c char based strings correctly.

The class \ref boost::locale::generator "generator" provides tools to generate the locales we need. The simplest way to use
\c generator is to create a locale and set it as the global one:

\code
    #include <boost/locale.hpp>
    
    using namespace boost::locale;
    int main()
    {
        generator gen;
        // Create locale generator 
        std::locale::global(gen("")); 
        // "" - the system default locale, set
        // it globally
    }
\endcode

Of course we can also specify the locale manually

\code
    std::locale loc = gen("en_US.UTF-8"); 
    // Use English, United States locale
\endcode

\note

-   Even if your application uses wide strings everywhere, you should specify the
    8-bit encoding to use for 8-bit stream IO operations like \c cout or \c fstream.
    .
-   The default locale is defined by the environment variables \c LC_CTYPE , \c LC_ALL , and \c LANG
    in that order (i.e. \c LC_CTYPE first and \c LANG last). On Windows, the library
    also queries the \c LOCALE_USER_DEFAULT option in the Win32 API when these variables
    are not set.

\b Tip: Prefer using UTF-8 Unicode encoding over 8-bit encodings like the ISO-8859-X ones.

By default the generated locales include all supported categories and character types. However, if your
application uses only 8-bit encodings, only wide-character encodings, or only specific facets, you can
limit the facet generation to specific categories and character types by calling the
\ref boost::locale::generator::categories() "categories" and \ref boost::locale::generator::characters() "characters"
member functions of the \ref boost::locale::generator "generator" class.

For example:

\code    
    generator gen;
    gen.characters(wchar_t_facet);
    gen.categories(collation_facet | formatting_facet);
    std::locale::global(gen("de_DE.UTF-8"));
\endcode

\page collation Collation 

Boost.Locale provides a \ref boost::locale::collator "collator" class, derived from \c std::collate, that adds support for
primary, secondary, tertiary, quaternary and identical comparison levels. They can be approximately defined as:

-# Primary -- ignore accents and character case, comparing base letters only. For example "facade" and "Façade" are the same.
-# Secondary -- ignore character case but consider accents. "facade" and "façade" are different but "Façade" and "façade" are the same.
-# Tertiary -- consider both case and accents: "Façade" and "façade" are different. Ignore punctuation.
-# Quaternary -- consider all case, accents, and punctuation. The words must be identical in terms of Unicode representation.
-# Identical -- as quaternary, but compare code points as well.

There are two ways of using the \ref boost::locale::collator "collator" facet: directly, by calling its member functions \ref boost::locale::collator::compare() "compare", \ref boost::locale::collator::transform() "transform" and \ref
boost::locale::collator::hash() "hash", or indirectly by using the \ref boost::locale::comparator "comparator" template
class in STL algorithms.

For example:

\code
    wstring a=L"Façade", b=L"facade";
    bool eq = 0 == use_facet<collator<wchar_t> >(loc).compare(collator_base::secondary,a,b);
    wcout << a <<L" and "<<b<<L" are " << (eq ? L"identical" : L"different")<<endl;
\endcode

\c std::locale is designed to be useful as a comparison class in STL collections and algorithms.
To get similar functionality with comparison levels, you must use the comparator class.

\code
    std::map<std::string,std::string,comparator<char,collator_base::secondary> > strings;
    // Now strings uses the default system locale for string comparison
\endcode

You can also set a specific locale or level when creating and using the \ref boost::locale::comparator "comparator" class:

\code
    comparator<char> comp(some_locale,some_level);
    std::map<std::string,std::string,comparator<char> > strings(comp);
\endcode

\page conversions Conversions

There is a set of functions that perform basic string conversion operations: upper, lower and title case conversions, case folding
and Unicode normalization. These are \ref boost::locale::to_upper "to_upper" , \ref boost::locale::to_lower "to_lower", \ref boost::locale::to_title "to_title", \ref boost::locale::fold_case "fold_case" and \ref boost::locale::normalize "normalize".

You may notice that there are existing functions \c to_upper and \c to_lower in the Boost.StringAlgo library.
The difference is that these function operate over an entire string instead of performing incorrect character-by-character conversions.

For example:

\code
    std::wstring gruben = L"grüßen";
    std::wcout << boost::algorithm::to_upper_copy(gruben) << " " << boost::locale::to_upper(gruben) << std::endl;
\endcode

Would give in output:

\verbatim
GRÜßEN GRÜSSEN
\endverbatim

Where a letter "ß" was not converted correctly to double-S in first case because of a limitation of \c std::ctype facet.

\note

-   \ref boost::locale::normalize() "normalize" operates only on Unicode-encoded strings, i.e.: UTF-8, UTF-16 and UTF-32 depending on the
    character width. So be careful when using non-UTF encodings as they may be treated incorrectly.
-   \ref boost::locale::fold_case() "fold_case" is generally a locale-independent operation, but it receives a locale as a parameter to
    determine the 8-bit encoding.
-   All of these functions can work with an STL string, a NUL terminated string, or a range defined by two pointers. They always
    return a newly created STL string.
-   The length of the string may change, see the above example.

\page formatting_and_parsing Numbers, Time and Currency formatting and parsing

All formatting and parsing is performed via the \c iostream STL library. Each of the above information types is represented as a number.
The formatting information is set using iostream manipulators. All manipulators are placed in the boost::locale::as namespace.

For example:

\code
    cout << as::currency << 123.45 << endl;
    // display 123.45 in local currency representation.
    cin >> as::currency >> x ;
    // Parse currency representation and store it in x
\endcode

There is a special manipulator \c as::posix that "unsets" locale-specific settings and returns them to the default \c iostream formatting
and parsing methods. Please note, such formats may still be localized by the default \c std::num_put and \c std::num_get facets.

\section numbers_formatting Numbers and number manipulators

Here are the manipulators for number formatting:

-   \c as::number -- format number according to local specifications, it takes into account various \c std::ios_base flags like scientific
    format and precision.
    .
-   \c as::percent -- format number as "percent" format. For example:
    \code
        cout << as::percent << 0.25 <<endl;
    \endcode
    Would create an output that may look like this:
    \verbatim
    25%
    \endverbatim
    .
-   \c as::spellout -- spell the number. For example, under the English locale, 103 may be displayed as "one hundred three".
    \b Note: not all locales provide rules for spelling numbers. In such a case the number would be displayed in decimal format.
    .
-   \c as::ordinal -- display an order-of element. For example "2" would be displayed as "2nd" under the English locale. As in
    the above case, not all locales provide ordinal rules.

\section currency_formatting Currency formatting

These are the manipulators for currency formatting:

-   \c as::currency -- set the format to currency mode.
-   \c as::currency_iso -- change the currency format to international, like "USD" instead of "$". This flag is supported
    when using ICU 4.2 and above.
-   \c as::currency_national -- change currency format to national, like "$".
-   \c as::currency_default -- return to the default (national) currency format.

\note \c as::currency_XYZ  manipulators have no effect on general formatting, only on the currency format. You must use both currency
and number manipulators to use a non-default format.

\section date_and_time_formatting Date and Time formatting

Dates and times are represented as POSIX time. When date-time formatting is turned on in the \c iostream, each number is treated as a
POSIX time. The number may be an integer or a double.

There are four major manipulators for Date and Time formatting:

-   \c as::date -- date only
-   \c as::time -- time only
-   \c as::datetime -- both date and time
-   \c as::ftime -- parameterized manipulator that allows specification of time in the format that is used in the \c strftime function.
    \b Note: not all formatting flags of \c strftime are supported.

For example:

\code
    double now=time(0);
    cout << "Today is "<< as::date << now << " and tommorrow is " << now+24*3600 << endl;
    cout << "Current time is "<< as::time << now << endl;
    cout << "The current weekday is "<< as::ftime("%A") << now << endl;
\endcode

More fine-grained control of date-time formatting is also available:

-   \c as::time_default , \c as::time_short , \c as::time_medium , \c as::time_long , \c as::time_full  -- change time formatting.
-   \c as::date_default , \c as::date_short , \c as::date_medium , \c as::date_long , \c as::date_full  -- change date formatting.

These manipulators, when used together with the \c as::date, \c as::time, or \c as::datetime manipulators, change the date-time representation.
The default format is medium.


By default, the date and time are shown in the local time zone. This behavior may be changed with the following manipulators:

-   \c as::gmt -- display date and time in GMT.
-   \c as::local_time  -- display in local time format (default).
-   \c as::time_zone  -- parameterized manipulator that sets the time-zone ID for date-time formatting and parsing. It
    takes a string parameter that represents the time zone ID.

For example:

\code
    double now=time(0);
    cout << as::datetime << as::locale_time << "Locale time is: "<< now << endl;
    cout << as::gmt << "GMT Time is: "<< now <<endl;
    cout << as::time_zone("EST") << "Eastern Standard Time is: "<< now <<endl;
\endcode

There is a list of supported \c strftime flags by ICU backend:

-   \c \%a  -- Abbreviated  weekday (Sun.)
-   \c \%A  -- Full weekday (Sunday)
-   \c \%b  -- Abbreviated month (Jan.)
-   \c \%B  -- Full month (January)
-   \c \%c  -- Locale date-time format. \b Note: prefer using \c as::datetime
-   \c \%d  -- Day of Month [01,31]
-   \c \%e  -- Day of Month [1,31]
-   \c \%h  -- Same as \c \%b 
-   \c \%H  -- 24 clock hour [00,23]
-   \c \%I  -- 12 clock hour [01,12]
-   \c \%j  -- Day of year [1,366]
-   \c \%m  -- Month [01,12]
-   \c \%M  -- Minute [00,59]
-   \c \%n  -- New Line
-   \c \%p  -- AM/PM in locale representation
-   \c \%r  -- Time with AM/PM, same as \c \%I:\%M:\%S \%p 
-   \c \%R  -- Same as \c \%H:\%M 
-   \c \%S  -- Second [00,61]
-   \c \%t  -- Tab character
-   \c \%T  -- Same as \c \%H:\%M:\%S 
-   \c \%x  -- Local date representation. **Note:** prefer using \c as::date
-   \c \%X  -- Local time representation. **Note:** prefer using \c as::time
-   \c \%y  -- Year [00,99]
-   \c \%Y  -- 4 digits year. (2009)
-   \c \%Z  -- Time Zone
-   \c \%\%  -- Percent symbol

Unsupported \c strftime flags are: \c \%C , \c \%u , \c \%U , \c \%V , \c \%w , \c \%W . Also, the \c O and \c E modifiers are not supported.


\b General \b recommendations

- Prefer using generic date-time manipulators rather than specifying the full format using \c as::ftime.
- Remember that current calendars may be not Gregorian.


\section formatting_internals Internals

Formatting information is stored in a stream class by using the \c xalloc, \c pword, and \c register_callback  member functions
of \c std::ios_base . All the information is stored and managed using a special object bound to \c iostream, and the manipulators just
change its state.

When a number is written to or read from the stream, a custom Boost.Locale facet accesses the object and checks the required formatting
information. Then it creates a special object that actually formats the number and caches it in the \c iostream. The
next time a number is written to the stream, the same formatter would be used unless some flags had changed and formatter object is
invalid.

\page messages_formatting Messages Formatting (Translation)

- \ref messages_formatting_into
- \ref msg_loading_dictionaries
- \ref message_translation
    - \ref indirect_message_translation
    - \ref plural_forms 
    - \ref multiple_gettext_domain
    - \ref direct_message_translation
- \ref extracting_messages_from_code
- \ref msg_qna

\section messages_formatting_into Introduction

Messages formatting is probably the most important part of localization --- making your application speak in the user's language.

Boost.Locale uses the <a href="http://www.gnu.org/software/gettext/">GNU Gettext</a> localization model.
We recommend you read the general <a href="http://www.gnu.org/software/gettext/manual/gettext.html">documentation</a> of GNU Gettext,
as it is outside the scope of this document.

The model is:

-   First, our application \c foo is prepared for localization by calling the \ref boost::locale::translate() "translate" function 
    for each message used in user interface.
    .
    For example:
    \code
        cout << "Hello World" << endl;
    \endcode
    Is change to
    .
    \code
        cout << translate("Hello World") << endl;
    \endcode
-   Then all messages are extracted from the source code and a special \c foo.po file is generated that contains all of the
    original English strings.
    .
    \verbatim
        ...
        msgid "Hello World"
        msgstr ""
        ...
    \endverbatim
-   The \c foo.po file is translated for the supported locales. For example, \c de.po, \c ar.po, \c en_CA.po , and \c he.po.
    .
    \verbatim
        ...
        msgid "Hello World"
        msgstr "שלום עולם"
    \endverbatim
    And then compiled to the binary \c mo format and stored in the following file structure:
    .
    \verbatim
        de
        de/LC_MESSAGES
        de/LC_MESSAGES/foo.mo
        en_CA/
        en_CA/LC_MESSAGES
        en_CA/LC_MESSAGES/foo.mo
        ...
    \endverbatim
    .
    When the application starts, it loads the required dictionaries. Then when the \c translate function is called and the message is written
    to an output stream, a dictionary lookup is performed and the localized message is written out instead.

\section msg_loading_dictionaries Loading dictionaries

All the dictionaries are loaded by the generator class. To use localized strings in the application you need to specify the following:

-# The search path of the dictionaries
-# The application domain (or name)

This is done by calling the following member functions of the \c generator class:

-   \ref boost::locale::generator::add_messages_path() "add_messages_path" -- add the root path to the dictionaries.
    .
    For example: if the dictionary is located at \c /usr/share/locale/ar/LC_MESSAGES/foo.mo, then path should be \c /usr/share/locale.
    .
-   \ref boost::locale::generator::add_messages_domain() "add_messages_domain" -- add the domain (name) of the application. In the above case it would be "foo".

At least one domain and one path should be specified in order to load dictionaries.

As an example, our first fully localized program:

\code
    #include <boost/locale.hpp>
    #include <iostream>

    using namespace std;
    using namespace boost::locale;

    int main()
    {
        generator gen;

        // Specify location of dictionaries
        gen.add_messages_path(".");
        gen.add_messages_domain("hello");

        // Generate locales and imbue them to iostream
        locale::global(gen(""));
        cout.imbue(locale());

        // Display a message using current system locale
        cout << translate("Hello World") << endl;
    }
\endcode


\section message_translation Message Translation
\subsection indirect_message_translation Indirect Message Translation

The basic function that allows us to translate a message is boost::locale::translate() family of functions:

-   Basic message translation:\n
    Translate a message, or a message in a given context. The source text is \b not copied.
    .
    -   boost::locale::translate(char const *message)
    -   boost::locale::translate(char const *context,char const *message)
    .
    Translate a message, or a message in a given context. The source text \b is not copied.
    .
    -   boost::locale::translate(std::string const &message)
    -   boost::locale::translate(std::string const &context,std::string const &message)
    Plural form translation:\n
    Translate a message, or a message in a given context. The source text is \b not copied.
    .
    -   boost::locale::translate(char const *single,char const *plural,int number)
    -   boost::locale::translate(char const *context,char const *single,char const *plural,int number)
    .
    Translate a message, or a message in a given context. The source text \b is not copied.
    .
    -   boost::locale::translate(std::string const &single,std::string const &plural,int number)
    -   boost::locale::translate(std::string const &context,std::string const &single,std::string const &plural,int number)
    .
    
These functions return a special Proxy object of type \ref boost::locale::message "message". It holds all the required
information for string formatting.
When this object is written to an output \c ostream, it performs a dictionary lookup of the message according to the locale
imbued in \c iostream.

If the message is found in the dictionary it is written to the output stream, otherwise the original string is written to the stream.

For example:

\code
    std::cout << boost::locale::tanslate("Hello World!") << std::endl;
\endcode

This allows the program to postpone translation of the message until the translation is actually needed, even to different
locale targets.

\code
    // Several output stream that we write a message to
    // English, Japaneese, Hebrew etc.
    // Each one them has installed std::locale object that represents
    // their specific locale
    std::ofstream en,ja,he,de,ar;
    std::wfstream w_ar;

    // Send single message to multiple streams
    void send_to_all(message const &msg)
    {
        // in each of the cases below
        // the message is translated to different
        // language
        en << msg;
        ja << msg
        he << msg;
        de << msg;
        ar << msg;
        w_ar << msg;
    }

    main()
    {
        ...
        send_to_all(translate("Hello World"));
    }
\endcode

\note

-   \c message can be implicitly converted to each type of supported string (i.e. \c std::string, \c std::wstring etc.) using 
    the global locale:
    .
    \code
        std::wstring msg = translate("Do you want to open the file?");
    \endcode
-   \c message can be explicitly converted to a string using the \c str<CharType> member function for a specific locale.
    .
    \code
        std::wstring msg = translate("Do you want to open the file?").str<wchar_t>(some_locale)
    \endcode


\subsection plural_forms Plural Forms

GNU Gettext catalogs has simple, robust and yet powerful plural forms support. We recommend the
original GNU documentation <a href="http://www.gnu.org/software/gettext/manual/gettext.html#Plural-forms">here</a>.

Let's try to solve a simple problem, displaying a message to the user:

\code
    if(files == 1)
        cout << translate("You have 1 file in the directory") << endl;
    else
        cout << format(translate("You have {1} files in the directory")) % files << endl;
\endcode

This very simple task becomes quite complicated when we deal with languages other than English. Many languages have more
than two plural forms. For example, in Hebrew there are special forms for single, double, plural, and plural above 10.
They can't be distinguished by the simple rule "is \c n 1 or not".

The correct solution is:

\code
    cout << format(translate("You have 1 file in the directory",
                            "You have {1} files in the directory",files)) % files << endl;
\endcode

Where translate receives the singular and plural forms of the original string and the number it should be formatted for.
On the other side, a special entry in the dictionary specifies the rule to choose the correct plural form in the target language.
For example, the Slavic language family has 3 plural forms, that can be chosen using following equation:

\code
    plural=n%10==1 && n%100!=11 ? 0 : n%10>=2 && n%10<=4 && (n%100<10 || n%100>=20) ? 1 : 2;
\endcode

Such an equation is stored in the dictionary, and is evaluated during translation to supply the correct form.
For more detailed information please refer to GNU Gettext: <a href="http://www.gnu.org/software/gettext/manual/gettext.html#Plural-forms">11.2.6 Additional functions for plural forms</a>

\subsection adding_context_information Adding Context Information

In many cases it is not sufficient to provide only the original English string to get the correct translation.
You sometimes need to provide some context information. In German, for example, a button labeled "open" is translated to 
"öffnen" in the context of "opening a file", or to "aufbauen" in the context of opening an internet connection.

In these cases you must add some context information to the original string, by adding a comment.

\code
    button->setLabel(translate("File","open"));
\endcode

The context information is provided as the first parameter to the \ref boost::locale::translate(char const*,char const*) "translate"
function in both singular and plural forms. The translator would see this context information and would be able to translate the
"open" string correctly.

For example, this is how the \c po file would look:

\code    
    msgctxt "File"
    msgid "open"
    msgstr "öffnen"
    
    msgctxt "Internet Connection"
    msgid "open"
    msgstr "aufbauen"
\endcode

\note Context information requires more recent versions of the gettext tools (>=0.15) for extracting strings and
formatting message catalogs.


\subsection multiple_gettext_domain Working with multiple messages domains

In some cases it is useful to work with multiple message domains.

For example, if an application consists of several independent modules, it may 
have several domains - a separate domain for each module.

For example, developing a FooBar office suite we might have:

- a FooBar Word Processor, using the "foobarwriter" domain
- a FooBar Spreadsheet, using the "foobarspreadsheet" domain
- a FooBar Spell Checker, using the "foobarspell" domain
- a FooBar File handler, using the "foobarodt" domain

There are three ways to use non-default domains:

-   When working with \c iostream, you can use the parameterized manipulator \ref
    boost::locale::as::domain "as::domain(std::string const &)", which allows switching domains in a stream:
    .
    \code
        cout << as::domain("foo") << translate("Hello") << as::domain("bar") << translate("Hello");
        // First translation is taken from dictionary foo and the other from dictionary bar
    \endcode
-   You can specify the domain explicitly when converting a \c message object to a string:
    \code
        std::wstring foo_msg = translate("Hello World").str<wchar_t>("foo");
        std::wstring bar_msg = translate("Hello World").str<wchar_t>("bar");
    \endcode
-   You can specify the domain directly using a \ref direct_message_translation "convenience" interface:
    \code
        MessageBox(dgettext("gui","Error Occured"));
    \endcode

\subsection direct_message_translation Direct translation (Convenience Interface)

Many applications do not write messages directly to an output stream or use only one locale in the process, so
calling <tt>translate("Hello World").str<wchar_t>()</tt>  for a single message would be annoying. Thus Boost.Locale provides
GNU Gettext-like localization functions for direct translation of the messages. However, unlike the GNU Gettext functions,
the Boost.Locale translation functions provide an additional optional parameter (locale), and support wide, u16 and u32 strings.

The GNU Gettext like functions have following prototypes:


- Ordinary translation of messages, in singular and plural form:
    \code
        std::string boost::locale::gettext(char const *message,std::locale const &l=std::locale());
        std::string boost::locale::ngettext(char const *single,char const *plural,std::locale const &l=std::locale());
    \endcode
- Message translation with context information:
    \code
        std::string boost::locale::pgettext(char const *context,char const *message,std::locale const &l=std::locale());
        std::string boost::locale::npgettext(char const *context,char const *single,char const *plural,std::locale const &l=std::locale());
    \endcode
- Message translation in a specific domain:
    \code
        std::string boost::locale::dgettext(char const *domain,char const *message,std::locale const &l=std::locale());
        std::string boost::locale::dngettext(char const *domain,char const *single,char const *plural,std::locale const &l=std::locale());
    \endcode
- Message translation in a specific domain with context information:
    \code
        std::string boost::locale::dgettext(char const *domain,char const *context,char const *message,std::locale const &l=std::locale());
        std::string boost::locale::dngettext(char const *domain,char const *context,,char const *single,char const *plural,std::locale const &l=std::locale());
    \endcode


All of these functions can have a prefix of \c w, \c u16  or \c u32  to return \c std::wstring, C++0x \c std::u16string  
or C++0x \c std::u32string respectively. For example:

\code
    MessageBoxW(0,wpgettext("File Dialog","Open?").c_str(),wgettext("Question").c_str(),MB_YESNO);
\endcode


\section extracting_messages_from_code Extracting messages from the source code

There are many tools to extract messages from the source code into the \c .po file format. The most
popular and "native" tool is \c xgettext which is installed by default on most Unix systems and freely downloadable
for Windows.

For example, we have a source file called \c dir.cpp that prints:

\code
    cout << translate("Listing of catalog {1}:") % file_name << endl;
    cout << translate("Catalog {1} contains 1 file","Catalog {1} contains {2,num} files",files_no) 
            % file_name % files_no << endl;
\endcode

Now we run:

    xgettext --keyword=translate:1,1t --keyword=translate:1,2,3t dir.cpp

And a file called \c messages.po created that looks like this (approximately):

\code
    #: dir.cpp:1
    msgid "Listing of catalog {1}:"
    msgstr ""
    
    #: dir.cpp:2
    msgid "Catalog {1} contains 1 file"
    msgid_plural "Catalog {1} contains {2,num} files"
    msgstr[0] ""
    msgstr[1] ""
\endcode

This file can be given to translators to adapt it to specific languages.

We used the \c --keyword  parameter of \c xgettext to make it suitable for extracting messages from 
source code localized with Boost.Locale, searching for <tt>translate()</tt> function calls instead of the default <tt>gettext()</tt>
and <tt>ngettext()</tt> ones.
The first parameter <tt>--keyword=translate:1,1t</tt> provides the template for basic messages: a \c translate function that is
called with 1 argument (1t) and the first message is taken as the key. The second one <tt>--keyword=translate:1,2,3t</tt> is used
for plural forms.
It tells \c xgettext to use a <tt>translate()</tt> function call with 3 parameters (3t) and take the 1st and 2nd parameter as keys. An 
additional marker \c Nc can be used to mark context information.

The full set of xgettext parameters suitable for Boost.Locale is:

\code
    xgettext --keyword=translate:1,1t --keyword=translate:1c,2,2t       \
             --keyword=translate:1,2,3t --keyword=translate:1c,2,3,4t   \
             --keyword=gettext:1 --keyword=pgettext:1c,2                \
             --keyword=ngettext:1,2 --keyword=npgettext:1c,2,3          \
             --keyword=wgettext:1 --keyword=wpgettext:1c,2              \
             --keyword=wngettext:1,2 --keyword=wnpgettext:1c,2,3        \
             --keyword=u16gettext:1 --keyword=u16pgettext:1c,2          \
             --keyword=u16ngettext:1,2 --keyword=u16npgettext:1c,2,3    \
             --keyword=u32gettext:1 --keyword=u32pgettext:1c,2          \
             --keyword=u32ngettext:1,2 --keyword=u32npgettext:1c,2,3    \
             source_file_1.cpp ... source_file_N.cpp
\endcode

Of course, if you do not use "gettext" like translation, or you do not use wide or C++0x u16/u32 strings, you
may ignore those parameters.

\subsection msg_qna Questions and Answers

-   Do I need GNU Gettext to use Boost.Locale?
    \n
    Boost.Locale provides a run-time environment to load and use GNU Gettext message catalogs, but it does
    not provide tools for generation, translation, compilation and managment of these catalogs.
    Boost.Locale only reimplements the GNU Gettext libintl.
    \n
    You would probably need:
    \n
    -#  Boost.Locale itself -- for runtime.
    -#  A tool for extracting strings from source code, and managing them: GNU Gettext provides good tools, but other
        implementations are available as well.
    -#  A good translation program like <a href="http://userbase.kde.org/Lokalize">Lokalize</a>, <a href="http://www.poedit.net/">Pedit</a> or <a href="http://projects.gnome.org/gtranslator/">GTranslator</a>.
    
-   Why doesn't Boost.Locale provide tools for extracting and management of message catalogs. Why should
    I use GPL-ed software? Are my programs or message catalogs affected by its license?
    \n
    -#  Boost.Locale does not link to or use any of the GNU Gettext code, so you need not worry about your code as
        the runtime library is fully reimplemented.
    -#  You may freely use GPL-ed software for extracting and managing catalogs, the same way as you are free to use
        a GPL-ed editor. It does not affect your message catalogs or your code.
    -#  I see no reason to reimplement well debugged, working tools like \c xgettext, \c msgfmt, \c msgmerge that
        do a very fine job, especially as they are freely available for download and support almost any platform.

-   Is there any reason to prefer the Boost.Locale implementation to the original GNU Gettext runtime library?
    In either case I would probably need some of the GNU tools.
    \n
    There are two important differences between the GNU Gettext runtime library and the Boost.Locale implementation:
    \n
    -#  The GNU Gettext runtime supports only one locale per process. It is not thread-safe to use multiple locales
        and encodings in the same process. This is perfectly fine for applications that interact directly with 
        a single user like most GUI applications, but is problematic for services and servers.
    -#  The GNU Gettext API supports only 8-bit encodings, making it irrelevant in environments that natively use
        wide strings.

*/


/*!

\page charset_handling Character Set Conversions

\section codecvt Convenience Interface

Boost.Locale provides \ref boost::locale::conv::to_utf() "to_utf"  and \ref boost::locale::conv::from_utf() "from_utf"  functions in the \c boost::locale::conv namespace. They are simple and convenient functions to convert a string to and from UTF-8/16/32 strings and strings using other encodings.

For example:

\code
    std::string utf8_string = to_utf<char>(latin1_string,"Latin1");
    std::wstring wide_string = to_utf<wchar_t>(latin1_string,"Latin1");
    std::string latin1_string = from_utf(wide_string,"Latin1");
\endcode


This function may use an explicit encoding name like "Latin1" or "ISO-8859-8", or use std::locale as a parameter to fetch this information from it.
It also receives a policy parameter that tells it how to behave if the conversion can't be performed (i.e. an illegal or unsupported character is found).
By default this function skips all illegal characters and tries to do the best it can, however, it is possible ask it to throw 
a \ref boost::locale::conv::conversion_error "conversion_error" exception by passing the \c stop flag to it:

\code
    std::wstring s=to_utf<wchar_t>("\xFF\xFF","UTF-8",stop); 
    // Throws because this string is illegal in UTF-8
\endcode

\section codecvt_codecvt std::codecvt facet 

Boost.Locale provides stream codepage conversion facets based on the \c std::codecvt facet.
This allows conversion between wide-character encodings and 8-bit encodings like UTF-8, ISO-8859 or Shift-JIS.

Most of compilers provide such facets, but:

-   Under Windows MSVC does not support UTF-8 encodings at all.
-   Under Linux the encodings are supported only if the required locales are generated. For example
    it may be impossible to create a \c he_IL.CP1255  locale even when the \c he_IL  locale is available.

Thus Boost.Locale provides an option to generate code-page conversion facets for use with 
Boost.Iostreams filters or \c std::wfstream. For example:

\code
    std::locale loc= generator().generate("he_IL.UTF-8");
    std::wofstream file.
    file.imbue(loc);
    file.open("hello.txt");
    file << L"שלום!" << endl;
\endcode

Would create a file \c hello.txt encoded as UTF-8 with "שלום!" (shalom) in it.

\section codecvt_iostreams_integration Integration with Boost.Iostreams

You can use the \c std::codecvt facet directly,  but this is quite tricky and
requires accurate buffer and error management.

You can use the \c boost::iostreams::code_converter class for stream-oriented
conversions between the wide-character set and narrow locale character set.

This is a sample program that converts wide to narrow characters for an arbitrary
stream:

\code
#include <boost/iostreams/stream.hpp>
#include <boost/iostreams/categories.hpp> 
#include <boost/iostreams/code_converter.hpp>

#include <boost/locale.hpp>
#include <iostream>

namespace io = boost::iostreams;

// Device that consumes the converted text,
// In our case it just writes to standard output
class consumer {
public:
    typedef char char_type;
    typedef io::sink_tag category;
    std::streamsize write(const char* s, std::streamsize n)
    {
        std::cout.write(s,n);
        return n;
    }
};


int main()
{ 
    // the device that converts wide characters
    // to narrow
    typedef io::code_converter<consumer> converter_device;
    // the stream that uses this device
    typedef io::stream<converter_device> converter_stream;


    consumer cons;
    // setup out converter to work
    // with he_IL.UTF-8 locale 
    converter_device dev;
    boost::locale::generator gen;
    dev.imbue(gen("he_IL.UTF-8"));
    dev.open(cons);
    converter_stream stream;
    stream.open(dev);
    // Now wide characters that are written
    // to the stream would be given to
    // our consumer as narrow characters 
    // in UTF-8 encoding
    stream << L"שלום" << std::flush;
}

\endcode


\section codecvt_limitations Limitations of std::codecvt

The Standard does not provides any information about \c std::mbstate_t that could be used to save
intermediate code-page conversion states. It leaves the definition up to the compiler implementation, making it
impossible to reimplement <tt>std::codecvt<wchar_t,char,mbstate_t></tt> for stateful encodings.
Thus, Boost.Locale's \c codecvt facet implementation may be used with stateless encodings like UTF-8,
ISO-8859, and Shift-JIS, but not with stateful encodings like UTF-7 or SCSU.

\b Recommendation: Prefer the Unicode UTF-8 encoding for \c char based strings and files in your application.

\note 

The implementation of codecvt for single byte encodings like ISO-8859-X and for UTF-8 is very efficent
and would allow fast conversion of the content, however its performance may be sub-optimal for
double-width encodings like Shift-JIS, due to the stateless problem described above.


\page boundary_analysys Boundary analysis

Boost.Locale provides a boundary analysis tool, allowing you to split text into characters, words, or sentences, and find appropriate
places for line breaks. 

\note A Unicode code point and a character are not equivalent. For example, the Hebrew word Shalom -- "שָלוֹם" consists
of 4 characters and 6 code points, where two code points are used for vowels (diacritical marks).

Boost.Locale provides 3 major classes for boundary analysis:

- boost::locale::boundary::mapping -- a special map that holds boundary points for the text.
- boost::locale::boundary::token_iterator  -- an iterator that returns chunks of text that were split by text boundaries
- boost::locale::boundary::break_iterator  -- an iterator that returns an iterator to the original text.

To perform boundary analysis, we first create a boundary mapping for the text.

\code
    using namespace boost::locale::boundary;
    std::string text="To be, or not to be?"
    // Create mapping of text for token iterator using default locale.
    mapping<token_iterator<std::string::const_iterator> > map(word,text.begin(),text.end()); 
    // Print all "words" -- chunks of word boundary
    for(token_iterator<std::string::const_iterator> it=map.begin(),e=map.end();it!=e;++it)
        std::cout <<"`"<< * it << "'"<< std::endl;
\endcode

Would print the list: "To", " ", "be", ",", " ", "or", " ", "not", " ", "to", " ", "be", "?"
You can also provide filters for better selection of the text chunks or boundaries you are interested in. For example:

\code
    map.mask(word_letters);
    // Tell newly created iterators to select words that contain letters only.
    for(token_iterator<std::string::const_iterator> it=map.begin(),e=map.end();it!=e;++it)
        std::cout <<"`"<< * it << "'"<< std::endl;
\endcode

Would print only: "To", "be", "or", "not", "to", "be", ignoring all non-words like punctuation.

The break_iterator has different role. Instead of returning text chunks, it returns the underlying
iterator used for source iteration. For example: you can select the two first sentences like this:

\code
    using namespace boost::locale::boundary;
    std::string const text="First sentence. Second sentence! Third one?"
    // Create a sentence boundary mapping and set the mask of boundaries
    // to select sentence terminators only, like "?", "." ignoring new lines.
    typedef break_iterator<std::string::const_iterator> iterator;
    mapping<iterator> map(sentence,map.begin(),map.end(),sentence_term);
    iterator p=map.begin();
    /// Advance p by two steps, make sure p is still valid;
    for(int i=0;i<2 && p!=text.end();i++)
        ++p;
    std::cout << "First two sentences are " << std::string(text.begin(),*p) << std::endl;
\endcode

Would print: "First sentence. Second sentence!"

\page localized_text_formatting Localized Text Formatting

The \c iostream manipulators are very useful, but when we create a messages for the user, sometimes we need something
like good old \c printf or \c boost::format.

Unfortunately \c boost::format has several limitations in context of localization:

-#  It renders all parameters using global locale rather than target \c ostream locale. For example:
    .
    \code
    std::locale::global(std::locale("en_US.UTF-8"));
    output.imbue(std::locale("de_DE.UTF-8"))
    output << boost::format("%1%") % 1234.345;
    \endcode
    .
    This would write "1,234.235" to output, instead of the "1.234,234" that is expected for "de_DE" locale
-#  It knows nothing about the new Boost.Locale manipulators.
-#  The \c printf-like syntax is very limited for formatting complex localized data, not allowing
    the formatting of dates, times, or currencies

Thus a new class, boost::locale::format, was introduced. For example:

\code
    wcout << wformat(L"Today {1,date} I would meet {2} at home") % time(0) % name <<endl
\endcode

Each format specifier is enclosed within \c {} brackets, is separated with a comma "," and
may have an additional option after an equals symbol '='. This option may be simple ASCII text or single-quoted localized text.
If a single-quote should be inserted within the text, it may be represented with a pair of single-quote characters.

Here is an example of a format string:

\verbatim
    "Ms. {1} had arrived at {2,ftime='%I o''clock'} at home. The exact time is {2,time=full}"
\endverbatim

The syntax is described by following grammar:

\verbatim
    format : '{' parameters '}'
    parameters: parameter | parameter ',' parameters;
    parameter : key ["=" value] ;
    key : [0-9a-zA-Z<>] ;
    value : ascii-string-excluding-"}"-and="," | local-string ; 
    local-string : quoted-text | quoted-text local-string;
    quoted-text : '[^']*' ;
\endverbatim


The following format key-value pairs are supported:

-   <tt>[0-9]+</tt> -- digits, the index of the formatted parameter -- required.
-   \c num or \c number -- format a number. Options are:
    .
    -   \c hex -- display in hexadecimal format
    -   \c oct -- display in octal format
    -   \c sci or \c scientific -- display in scientific format
    -   \c fix or \c fixed -- display in fixed format
    .
    For example, \c number=sci
-   \c cur or \c currency -- format currency. Options are:
    .
    -   \c iso -- display using ISO currency symbol.
    -   \c nat or \c national -- display using national currency symbol.
    .
-   \c per or \c percent -- format a percentage value.
-   \c date, \c time , \c datetime or \c dt -- format a date, a time, or a date and time. Options are:
    .
    -   \c s or \c short -- display in short format.
    -   \c m or \c medium -- display in medium format.
    -   \c l or \c long -- display in long format.
    -   \c f or \c full -- display in full format.
-   \c ftime with string (quoted) parameter -- display as with \c strftime. See \c as::ftime manipulator.
-   \c spell or \c spellout -- spell the number.
-   \c ord or \c ordinal -- format an ordinal number (1st, 2nd... etc)
-   \c left or \c < -- align-left.
-   \c right or \c > -- align-right.
-   \c width or \c w -- set field width (requires parameter).
-   \c precision or \c p -- set precision (requires parameter).
-   \c locale -- with parameter -- switch locales for the current operation. This command generates a locale
    with formatting facets, giving more fine grained control of formatting. For example:
    .
    \code
    cout << format("This article was published at {1,date=l} (Gregorian) {1,locale=he_IL@calendar=hebrew,date=l} (Hebrew)") % date;
    \endcode


The constructor for the \ref boost::locale::format "format" class can take an object of type \ref boost::locale::message "message", simplifying integration with message translation code.

For example:

\code
    cout<< format(translate("Adding {1} to {2}, we get {3}")) % a % b % (a+b) << endl;
\endcode

A formatted string can be fetched directly by using the \ref boost::locale::format::str() "str(std::locale const &loc=std::locale())" member function. For example:

\code
    std::wstring de = (wformat(translate("Adding {1} to {2}, we get {3}")) % a % b % (a+b)).str(de_locale);
    std::wstring fr = (wformat(translate("Adding {1} to {2}, we get {3}")) % a % b % (a+b)).str(fr_locale);
\endcode


\note  There is one significant difference between \c boost::format and \c boost::locale::format: Boost.Locale's format converts its
parameters only when written to an \c ostream or when the `str()` member function is called. It only saves references to the objects that
can be written to a stream.

This is generally not a problem when all operations are done in one statement, such as:

\code
    cout << format("Adding {1} to {2}, we get {3}") % a % b % (a+b);
\endcode

Because the temporary value of \c (a+b) exists until the formatted data is actually written to the stream. But following code is wrong:

\code
    format fmt("Adding {1} to {2}, we get {3}");
    fmt % a;
    fmt % b;
    fmt % (a+b);
    cout << fmt;
\endcode

Because the temporary value of \c (a+b) no longer exists when \c fmt is written to the stream. A correct solution would be:

\code
    format fmt("Adding {1} to {2}, we get {3}");
    fmt % a;
    fmt % b;
    int a_and_b = a+b;
    fmt % a_and_b;
    cout << fmt;
\endcode

\page dates_times_timezones Working with dates, times, timezones and calendars.

\section dates_times_timezones_intro Introduction
 
There are several important flaws in the standard C, C++ and Boost libraries that handle dates and time:

-#  The biggest flaw of most libraries that provide operations over dates is the fact that they only support
    the Gregorian calendar. \c boost::date_time , \c std::tm , and standard functions like \c localtime and \c gmtime,
    all assume the Gregorian calendar.
    .
-#  The information about local start of week is not provided.
    \n
    For example the standard C and C++ library has \c mktime and \c localtime, but they do not give
    user the information about the first day of week. This information is locale dependent.
    It is Monday in France and it is Sunday in United States.

Boost.Locale provides generic \ref boost::locale::date_time "date_time", and \ref boost::locale::calendar "calendar" classes 
that allow you to perform operations on dates and times for non-Gregorian calendars such as Hebrew, Islamic, Japanese and others.

\ref using_localization_backends "Non-ICU based backends" support the Gregorian calendar only.
Unlike \c boost::date_time, they fully aware of the local first day of week. Thus,
if the current day of week is Monday, than setting "current day of week" to Sunday would move the actual date 6 days
forward in Russian or French locales and move one day backward in USA and Israeli locales.

\section dates_times_timezones_dt Handling Dates and Time

- \ref boost::locale::calendar -- represents generic information about the calendar, independent from a specific time point. For example, you can get the maximum number of days in a month for a specific calendar.
- \ref boost::locale::date_time  -- represents a time point. It is constructed from a calendar and allows manipulation of various time periods.
- \ref boost::locale::period -- holds an enumeration of various periods, such as month, year, day, and hour, allowing
manipulation of dates and times. You can add periods, multiply them by integers, get or set them, or add them to
\ref boost::locale::date_time "date_time" objects.


For example:

\code
    using namespace boost::locale;
    date_time now; // Create date_time class with default calendar initialized to current time
    date_time tomorrow = now + period::day;
    cout << "Let's meet tomorrow at " << as::date << tomorrow << endl;
    date_time some_point = period::year * 1995 + period::january + period::day*1;
    // Set some_point's date to 1995-Jan-1.
    cout << "The "<< as::date << some_point " is the " 
        << as::ordinal << some_point / period::day_of_week_local << " day of the week"  << endl;
\endcode

You can calculate the difference between dates by dividing the difference by a period:

\code
    date_time now;
    cout << " There are " << (now + 2 * period::month - now) / period::day << " days "
            "between " << as::date << now << " and " << now + 2*period::month << endl;
\endcode

\ref boost::locale::date_time "date_time"  -- provides the member functions \ref boost::locale::date_time::minimum() "minimum" and
\ref boost::locale::date_time::maximum() "maximum" to get the information about smallest and largest
possible values of a certain period for a specific time.

For example, for February the <tt>maximum(period::date)</tt> would be 28 (or 29 for a leap year), and for January it would be 31.

\note Be very careful with assumptions about calendars. For example, in the Hebrew calendar, the
number of months is different for leap years and non-leap years.

We recommended you look at the \c calendar.cpp example provided with this library to get an understanding of how
to manipulate dates and times using these classes.

To convert between various calendar dates, you may get the current POSIX time via the
\ref boost::locale::date_time::time "time" member function.

For example:

\code
    using namespace boost::locale;
    using namespace boost::locale::period;
    generator gen;
    // Create locales with Hebrew and Gregorian (default) calendars.
    std::locale l_hebrew=gen("en_US@calendar=hebrew");
    std::locale l_gregorian=gen("en_US");
    
    // Create a Gregorian date from fields
    date_time greg(2010*year + february + 5*day,l_gregorian);
    // Assign a time point taken from the Gregorian date to date_time with
    // the Hebrew calendar
    date_time heb(greg.time(),l_hebrew);
    // Now we can query the year.
    std::cout << "Hebrew year is " << heb / year << std::endl;
\endcode

\note 

Non-ICU based backends support the same date-time range as \c mktime and \c localtime C library functions.

- Unix 32 bit: dates between 1901 and 2038
- Unix 64 bit: dates from 1 BC 
- Windows: dates from 1970. If the \c time_t is 32 bits wide (mingw), then the upper limit is year 2038

\section dates_times_timezones_tz Time Zone

The current operating system's time zone is used by default, however the time zone can be modified at
several different levels:

-#  Calendar level: you can specify a timezone when creating a new instance of \ref boost::locale::calendar
    in its constructor.
-#  iostream level: you can use \ref boost::locale::as::time_zone "as::time_zone" manipulator to set a specific
    time zone to the iostream so all dates and times would be represented in this time zone
-#  You can specify the default global time zone by calling: \ref boost::locale::time_zone::global(std::string const &).
    This time zone would be the default one for newly created iostream object and calendar instances.

\note

\ref using_localization_backends "Non-ICU based backends" support only two kinds of time zones:

-#  The current OS time zone, as it is handled by \c localtime and \c mktime the standard 
    library functions - the default time zone
-#  Simple time zone in format "GMT+HH:MM" - the time zone represented using fixed shift from
    the UTC without support of daylight saving time.


\section dates_times_timezones_io I/O Operations on date_time objects

Writing a \ref boost::locale::date_time "date_time" object to iostream is equivalent
to calling \ref boost::locale::date_time::time() "date_time::time()"
function and writing it result to the stream as a number - the POSIX time of the specific
time point.


\code
    using namespace boost::locale;
    date_time now;
    std::cout << now << std::endl;
\endcode

The example above would just print a number. Thus, you need to use iostream manipulators in order to display current date or time:

\code
    using namespace boost::locale;
    date_time now;
    std::cout << as::date << now << std::endl;
\endcode

This is important to remember that \c date_time object is alway rendered and parsed in the context
of the \c iostream's locale and time zone and not in the context of specific \c date_time object.

\section dates_times_timezones_qna Questions and Answers 


<b>Why should I use Boost.Locale over Boost.DateTime when I need Gregorian calendar only?</b>

-   Boost.DateTime is locale agnostic library and ignores the fact that the first day of week
    varies by the locale.
    .
-   Boost.Locale provides a unified access to date and time in time zone aware way.
    It represents a time as universal scalar - the POSIX time and over that build dates,
    local times and time-zones handling.
    \n
    For example, <tt>date_time(some_time.time() + 3600)</tt> may be not equal to
    <tt>some_time + hour</tt>, because of the daylight savings time.

<b>Why don't you use Boost.DateTime time zone support?</b>

Boost.DateTime's time zone support is broken. Time zones can not be represented with
a simple table of rules where daylight saving depend only on certain n'th day of week in month.
The daylight savings time may vary by year, political issues and many other things.

Most of the modern operating systems (Linux, *BSD, Mac OS X, OpenVMS) and many important software packages
(ICU, Java, Python) use so called Olson database in order to handle daylight saving time 
correctly.

If you need full time zone database support, then you should use ICU library.

\page locale_information Getting information about the current locale

The \c std::locale::name function provides very limited information about a locale. Such a name is platform-
and compiler-dependent, and is useless for Boost.Locale. There is no way to change it, so for all locales
created by Boost.Locale, \c name() returns the same value as \c name() for \c std::locale::classic().

Thus an additional facet was created, giving more precise information: boost::locale::info. It has the following member functions:

-   \ref boost::locale::info::name() "std::string name()" -- the full name of the locale, for example \c en_US.UTF-8
-   \ref boost::locale::info::language() "std::string language()" -- the ISO-639 language code of the current locale, for example "en".
-   \ref boost::locale::info::country() "std::string country()" -- the ISO-3199 country code of the current locale, for example "US".
-   \ref boost::locale::info::variant() "std::string variant()" -- the variant of current locale, for example "euro".
-   \ref boost::locale::info::encoding() "std::string encoding()" -- the encoding used for \c char based strings, for example "UTF-8"
-   \ref boost::locale::info::utf8() "bool utf8()" -- a fast way to check whether the encoding is UTF-8.

For example:

\code
    cout << "The language code is " << std::use_facet<boost::locale::info>(some_locale).language() << endl;
\endcode


\page working_with_multiple_locales Working with multiple locales

Boost.Locale allows you to work safely with multiple locales in the same process. As we mentioned before, the locale
generation process is not a cheap one. Thus, when we work with multiple locales and need to switch between them,
we recommend that you create all the locales you need when the program starts.

To simplify this process, the boost::locale::generator class has an option to cache all
generated locales. With this option, when you create a locale that was previously generated, it would be fetched
from the existing locale set instead. This operation is thread safe.

This option must be explicitly enabled by calling the \ref boost::locale::generator::locale_cache_enabled() "locale_cache_enabled"  member function of boost::locale::generator with \c true as the parameter.


For example:

\code
    generator gen;
    get.locale_cache_enabled(true);
    gen("en_US.UTF-8");
    gen("de_DE.UTF-8");
    gen("ja_JP.UTF-8");
    // Create all locales

    std::locale en=gen("en_US.UTF-8"); 
    // Fetch an existing locale from the cache
    std::locale ar=get("ar_EG.UTF-8");
    // Because ar_EG not in the cache, a new locale is generated (and cached)
\endcode

Then these locales can be imbued to \c iostreams or used directly as parameters in various functions.



\page using_localization_backends Using Localization Backends

By default, Boost.Locale uses ICU for all localization and text manipulation tasks.
This is the most powerful library available, but sometimes we don't need
the full power of this library or we want to reduce dependencies from third-party
libraries, and ICU is by no means a small library.

Boost.Locale provides an option to use non-ICU based localization
backends. Although usually less powerful, these often provide all you need:
message formatting, currency, date, time, number formatting, basic collation and 
case manipulation. They are implemented using the standard OS API or a C or C++ library.

\section when_to_use_non_icu_backends When to use non-ICU backends

There are situations when using non-ICU based localization is appropriate:

- Embedded systems, where the ICU library is very hefty.
- Applications where only basic features like message, date, and time formatting and
  basic collation are required, and using a third-party library like ICU would be too
  complicated.
- Performance. ICU is a very powerful library, but it is generally slower than the standard
  library. Sometimes it's better to use a simpler but faster localization backend.


\section non_icu_backends Non-ICU Backends

All of the alternate backends have these limitations:

- Only the Gregorian calendar is supported and it is based
  on capabilites of mktime functionality (including dates range)
- No boundary analysis.
- Case handing is very simple and based on single codepoint conversions,
  though they still handle UTF-8 better than the standard library.
- Time zone specification is very limited: either local time or a time zone
  in the format "GMT+HH:MM".
- No percent formatting, no spellout or ordinal number formatting.
- Collation, with exception of the \c winapi backend, is limited to a single level,
  similar to what is done by \c strcoll.


\subsection std_backend std - The standard C++ library backend

This localization backend is based on the standard C++ library.

It is supported on all platforms, but is only actually useful on platforms where
the standard library supports locales besides "C" and "POSIX": on Linux with GCC
or Intel compilers, and under the MSVC compiler.

It works around some common standard library bugs like invalid UTF-8 generation for numeric
formatting, and it gives otherwise-absent POSIX locales names and UTF-8 support under MSVC.

It is very useful when the compiler and the library actually give fine localization
support, like GCC under Linux or MSVC under Windows.

\subsection posix_backend posix - POSIX 2008 C library

This backend is based on the latest POSIX 2008 standards, and uses POSIX api functions like
\c newlocale, \c freelocale, \c strftime_l  etc. It is available on the Linux and Mac OS X
platforms.

It gives you simple and ready-made localization support, most notably under Mac OS X where
GCC's \c libstdc++ does not support locales.

\note The POSIX backend only supports UTF-8, single-byte, and double-byte encodings.

\subsection winapi_backend winapi - Win32 API.

The Win32API-based localization backend provides decent UTF-8/UTF-16 locale support.
It is based on Windows API functions like \c GetLocaleInfoW, \c LCMapStringW, \c GetDateFormatW etc and
provides good localization support even on the MinGW and Cygwin platforms, which normally have
problems with this.

\note

- You need GCC-4.x to use it.
- Only UTF-8 encoding is supported.

\section supported_features_by_backends Supported Features

<table border="1" sellpadding="5" sellspacing="3">
<tr>
  <th>Backend</th>
  <th>icu</th><th>posix</th><th>winapi</th><th>std</th>
</tr>
<tr>
  <th>Message Formatting</th>
  <td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td>
</tr>
<tr>
  <th>Non UTF-8 encodings</th>
  <td>Yes</td><td>Yes</td><td>No</td><td>Yes</td>
</tr>
<tr>
  <th>Date/Time Formatting/Parsing</th>
  <td>Yes</td><td>Formatting Only</td><td>Formatting Only</td><td>Formatting Only</td>
</tr>
<tr>
  <th>Monetary Formatting/Parsing</th>
  <td>Yes</td><td>Formatting Only</td><td>Formatting Only</td><td>Yes</td>
</tr>
<tr>
  <th>Number Formatting/Parsing</th>
  <td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td>
</tr>
<tr>
  <th>Numbers as Percent, Spelled Out</th>
  <td>Yes</td><td>No</td><td>No</td><td>No</td>
</tr>
<tr>
  <th>Case Manipulation</th>
  <td>Yes</td><td>Basic</td><td>Basic</td><td>Basic</td>
</tr>
<tr>
  <th>Collation</th>
  <td>Full</td><td>Linux - 1 level<br/>Mac OS X - broken</td><td>3 levels</td><td>1 level</td>
</tr>
<tr>
  <th>Calendar</th>
  <td>Yes</td><td>Gregorian Only</td><td>Gregorian Only</td><td>Gregorian Only</td>
</tr>
<tr>
  <th>Boundary Analysis</th>
  <td>Yes</td><td>No</td><td>No</td><td>No</td>
</tr>
<tr>
  <th>Unicode Normalization</th>
  <td>Yes</td><td>No</td><td>Vista and above</td><td>No</td>
</tr>
<tr>
  <th>C++0x characters</th>
  <td>Yes</td><td>No</td><td>No</td><td>Yes</td>
</tr>
<tr>
  <th>OS Support</th>
  <td>Any</td><td>Linux, Mac OS X</td><td>Windows, Cygwin</td><td>Any</td>
</tr>
<tr>
  <th>Useful on</th>
  <td>Any Platform</td><td>Linux and Mac OS X</td><td>Windows/MinGW/Cygwin</td><td>Linux with GCC or Intel<br/>Windows with MSVC</td>
</tr>
</table>


\section using_localization_backends Using Localization Backends

Accessing a localization backend is done via the boost::locale::localization_backend_manager class.

You can create your own boost::locale::localization_backend_manager by starting with a global backend
via the boost::locale::localization_backend_manager::global static member function and modifying it.

For example:

\code
    localization_backend_manager my = localization_backend_manager::global(); 
    // Get global backend

    my.select("std"); 
    // select \c std backend as default

    generator gen(my); 
    // create a generator that uses this backend.

    localization_backend_manager::global(my);
    // set this backend globally

    generator gen2();
    // now this one would use the new global backend.
\endcode

You can also create a mixture of several backends, using
for example \c icu for one kind of operation and \c std
for all others:

\code
    localization_backend_manager my = localization_backend_manager::global(); 
    // Get global backend

    my.select("std"); 
    // select std backend as default for all categories
    my.select("icu",boundary_facet); 
    // select icu backend for boundary analysis (since it is not supported by \c std)
\endcode

\page recommendations_and_myths Recommendations and Myths

\section recommendations Recommendations

-   The first and most important recommendation: prefer UTF-8 encoding for narrow strings --- it represents all
    supported Unicode characters and is more convenient for general use than encodings like Latin1.
-   Remember, there are many different cultures. You can assume very little about the user's language. His calendar
    may not have "January". It may be not possible to convert strings to integers using \c atoi because
    they may not use the "ordinary" digits 0..9 at all. You can't assume that "space" characters are frequent 
    because in Chinese the space character does not separate words. The text may be written from Right-to-Left or
    from Up-to-Down, and so on.
-   Using message formatting, try to provide as much context information as you can. Prefer translating entire 
    sentences over single words. When translating words, \b always add some context information.


\section myths Myths

\subsection myths_wide To use Unicode in my application I should use wide strings everywhere.

Unicode is not limited to wide strings. Both \c std::string and \c std::wstring
can hold and process Unicode text. More than that, the semantics of \c std::string
are much cleaner in multi-platform applications, because all "Unicode" strings are
UTF-8. "Wide" strings may be encoded in "UTF-16" or "UTF-32", depending
on the platform, so they may be even less convenient when dealing with Unicode than
\c char based strings.

\subsection myths_utf16 UTF-16 is the best encoding to work with.

There is common assumption that UTF-16 is the best encoding for storing information because it gives "shortest" representation
of strings.

In fact, it probably the most error-prone encoding to work with. The biggest issue is code points that lay outside of the BMP,
which must be represented with surrogate pairs. These characters are very rare and many applications are not tested with them.

For example:

-   Qt3 could not deal with characters outside of the BMP.
-   Editing a character with a codepoint above 0xFFFF often shows an unpleasant bug: for example, to erase
    such a character in Windows Notepad you have to press backspace twice.

So UTF-16 can be used for Unicode, in fact ICU and may other applications use UTF-16 as their internal Unicode representation, but
you should be very careful and never assume one-code-point == one-utf16-character.

\page building_boost_locale Building The library

Boost.Locale presently supports  CMake build system and Boost Build.

\note You need Boost 1.46 and above to use Boost.Build

- \ref building_boost_locale_bb
- \ref building_boost_locale_cmake
- \ref binary_compatibility


\section building_boost_locale_bb Building With Boost.Build

You need Boost 1.46 and above to use Boost.Build, it includes important
patches that allow you to build the library correctly.

\subsection bb_building_deps Dependencies

- Boost 1.46 and above.
- ICU library 3.6 or above is strongly recommended
- If no ICU library is given, iconv support is required under POSIX platforms.

\subsection bb_building_proc Building Process

First of all we need to prepare our sources of Boost with Boost.Locale

- Download latest version of Boost and extract its sources
- Download the latest version of Boost.Locale and extract its sources
- Copy boost and libs subdirectory of Boost.Locale sources into the location
  of boost sources.
- Bootstrap latest bjam version running bootstrap.sh or bootstrap.bat.

Now all you need to do is invoke bjam command:

\verbatim
./bjam --with-locale stage
\endverbatim

Or on Windows
\verbatim
.\bjam --with-locale stage
\endverbatim

If you are using custom ICU build or you are using Microsoft Windows
you need to provide a path to location of ICU library using \c -sICU_PATH option

For example:

-   If your icu build in placed at \c /opt/icu46 such that the files are placed like\n
    \c /opt/icu46/include/unicode/uversion.h\n
    \c /opt/icu46/include/unicode/calendar.h\n
    \c ... \n
    \c /opt/icu46/lib/libicudata.so \n
    \c /opt/icu46/lib/libicui18n.so \n
    \c ... \n
    then you need to provide an option \c -sICU_PATH=/opt/icu46
    \verbatim
    ./bjam --with-locale -sICU_PATH=/opt/icu46  stage
    \endverbatim
-   If your icu build in placed at <tt>c:\\icu46</tt> such that the files are placed like \n
    <tt>c:\\icu46\\include\\unicode\\uversion.h</tt>  \n
    <tt>c:\\icu46\\include\\unicode\\calendar.h</tt> \n
    <tt>...</tt> \n
    <tt>c:\\icu46\\bin\\icudt.dll</tt> \n
    <tt>c:\\icu46\\bin\\icuin.dll</tt> \n
    <tt>...</tt> \n
    <tt>c:\\icu46\\lib\\icudt.lib</tt> \n
    <tt>c:\\icu46\\lib\\icuin.lib</tt> \n
    <tt>...</tt> \n
    then you need to provide an option \c -sICU_PATH=c:\\icu46
    \verbatim
    .\bjam --with-locale -sICU_PATH=c:\icu46  stage
    \endverbatim

\note Don't forget to put both debug and release versions of ICU libraries in this path
when using Microsoft Visual Studio  so Boost.Build will link correctly debug and release
versions of boost_locale library.

\section bb_build_opts Build Options

Boost.Locale supports following options with values \c off or \c on

- \c boost.locale.icu=off disable build of ICU backend even if ICU library exists
- \c boost.locale.iconv=off or \c boost.locale.iconv=on enable or disable use of iconv
     library. It is off by default on Windows and Solaris
- \c boost.locale.winapi=off - disable winapi backend, it is on by default on Windows and Cygwin
- \c boost.locale.std=off or \c boost.locale.winapi=on Disable or enable std backends. \c std backend
     is disabled by default when using Sun Studio.
- \c boost.locale.posix=on or \c boost.locale.posix=off Enable or disable support of POSIX backend,
     it is on by default on Linux and Mac OS X

Also Boost.Locale supports following options

- \c -sICU_PATH=/path/to/location/of/icu - the location of custom ICU library
- \c -sICONV_PATH=/path/to/location/of/iconv - the location of custom iconv library


For example:

-   Build the library on Windows with ICU backend only:
    \verbatim
    .\bjam boost.locale.winapi=off boost.locale.std=off -sICU_PATH=c:\icu46 --with-locale stage
    \endverbatim
-   Build the library on Linux with std backend only
    \verbatim
    .\bjam boost.locale.posix=off boost.locale.icu=off --with-locale stage
    \endverbatim

\section bb_build_test Running Unit Tests

You can run unit tests by invoking \c bjam with \c libs/locale/test project parameter
\verbatim
./bjam libs/locale/test
\endverbatim

\section building_boost_locale_cmake Building With CMake

\note CMake build does not provide mangled library names like boost_locale-mt-gd.lib, so if you
relay on auto-linking use Boost.Build.

\subsection cmake_building_deps Dependencies

- CMake 2.6 and above.
- Boost 1.35 and above.
- Boost.Thread (when using ICU or when using Boost < 1.43)
- ICU library 3.6 or above is strongly recommended
- If no ICU library is given, iconv support is required under POSIX platforms.

\subsection cmake_building_proc Building Process

The library build should be fairly simple for users familiar with CMake.

\note

- MSVC Users: use \c nmake for building the library, MSVC projects are not supported!
- Windows users: don't forget to set the PATH environment variable to point to ICU's dlls.

The simplest way to build the library is:

-   Extract its sources
-   Go to the sources directory
-   Create a subdirectory named "build"
-   Go into this directory and run:
    \code
        cmake ..
        make
        make test
    \endcode
    For windows you may need to specify:
    \code
        cmake -DCMAKE_INCLUDE_PATH=/path/to/icu/include:/path/to/boost/include -DCMAKE_LIBRARY_PATH=/path/to/icu/lib ..
    \endcode
    And then:
    \code
        nmake
        nmake test
    \endcode
    Or
    \code
        make && make test
    \endcode
    Depending on your compiler.


\section cmake_build_opts Build Options

This options can be passed to CMake to configure the library to your needs.

- \c DISABLE_SHARED  - build only the static library
- \c DISABLE_STATIC  - build only the shared library
- \c DISABLE_ICU  - Disable the ICU backend (strongly discouraged)
- \c DISABLE_STD_BACKED  - Disable the "std" backend
- \c DISABLE_POSIX_BACKEND  - Disable the "posix" backend (ON by default on all but Linux and Mac OS X)
- \c DISABLE_WINAPI_BACKEND  - Disable the "winapi" backend (ON by default on POSIX platforms).
- \c DISABLE_ICONV  - Disable iconv-based conversion (ON by default on Windows)

Useful CMake options:

- \c CMAKE_INCLUDE_PATH  - path to the boost library (if not system-wide)
- \c CMAKE_INSTALL_PREFIX  - installation path
- \c CMAKE_BUILD_TYPE  - default is Debug on Windows/MSVC and RelWithDebInfo on all other platforms.

Examples:

- Build Boost.Locale with only the "icu" backend on Linux
    \code
        cmake -DDISABLE_POSIX_BACKEND=ON -DDISABLE_STD_BACKEND=ON -DDISABLE_ICONV=ON ..
    \endcode
- Build Boost.Locale with the "winapi" and "std" backends on Windows
    \code
        cmake -G "NMake Makefiles" -DDISABLE_ICU_BACKEND=ON -DCMAKE_INCLUDE_PATH=c:/boost_1_43_0 ..
    \endcode

\section binary_compatibility Binary Compatibility

Boost.Locale is built with binary compatibility in mind. Switching localization back ends on or off,
or using iconv or not, does not affect binary compatibility. So if a dynamic library was built
with all possible backends, other dynamic libraries compiled with, for example, only the \c std, \c posix 
or \c winapi backends would still be binary-compatible with it.

However this definitely has an effect on some features. For example, if you
try to use boundary analysis or a calendar facet when the library does not support the icu backend
you would get an exception.

\page appendix Appendix

\section appendix_toc Table of Contents 

- \ref rationale
- \ref default_encoding_under_windows
- \ref running_examples_under_windows 
- \ref glossary
- \ref tested_compilers_and_paltforms 
- \ref status_of_cpp0x_characters_support
- \ref special_thanks
- \ref copyright

\section rationale Design Rationale 

- \ref rationale_why
- \ref why_icu
- \ref why_icu_wrapper 
- \ref why_icu_api_is_hidden
- \ref why_gnu_gettext 
- \ref why_posix_names
- \ref why_linear_chunks
- \ref why_abstract_api
- \ref why_no_special_character_type

\subsection rationale_why Why is it needed?

Why do we need a localization library, when standard C++ facets (should) provide most of the required functionality:

- Case conversion is done using the \c std::ctype facet
- Collation is supported by \c std::collate and has nice integration with \c std::locale
- There are \c std::num_put , \c std::num_get , \c std::money_put , \c std::money_get , \c std::time_put and \c std::time_get for numbers,
    time, and currency formatting and parsing.
- There is a \c std::messages class that supports localized message formatting.

So why do we need such library if we have all the functionality within the standard library?

Almost every(!) facet has design flaws:

-  \c std::collate supports only one level of collation, not allowing you to choose whether case- or accent-sensitive comparisons
    should be performed.

-  \c std::ctype, which is responsible for case conversion, assumes that all conversions can be done on a per-character basis. This is
    probably correct for many languages but it isn't correct in general.
    .
    -# Case conversion may change a string's length. For example, the German word "grüßen" should be converted to "GRÜSSEN" in upper
    case: the letter "ß" should be converted to "SS", but the \c toupper function works on a single-character basis.
    -# Case conversion is context-sensitive. For example, the Greek word "ὈΔΥΣΣΕΎΣ" should be converted to "ὀδυσσεύς", where the Greek letter
    "Σ" is converted to "σ" or to "ς", depending on its position in the word.
    -# Case conversion cannot assume that a character is a single code point, which is incorrect for both the UTF-8 and UTF-16 encodings,
       where individual code-points are represented by up to 4 \c char 's or two \c wchar_t 's on the Windows platform. This makes
       \c std::ctype totally useless with these encodings.
-   \c std::numpunct and \c std::moneypunct do not specify the code points for digit representation at all,
    so they cannot format numbers with the digits used under Arabic locales. For example,
    the number "103" is expected to be displayed as "١٠٣" in the \c ar_EG locale.
    \n
    \c std::numpunct and \c std::moneypunct assume that the thousands separator is a single character. This is untrue
    for the UTF-8 encoding where only Unicode 0-0x7F range can be represented as a single character. As a result, localized numbers can't be
    represented correctly under locales that use the Unicode "EN SPACE" character for the thousands separator, such as Russian.
    \n
    This actually causes real problems under GCC and SunStudio compilers, where formatting numbers under a Russian locale creates invalid 
    UTF-8 sequences.
-   \c std::time_put and \c std::time_get have several flaws:
    -# They assume that the calendar is always Gregorian, by using \c std::tm for time representation, ignoring the fact that in many
       countries dates may be displayed using different calendars.
    -# They always use a global time zone, not allowing specification of the time zone for formatting. The standard \c std::tm doesn't
       even include a timezone field at all.
    -# \c std::time_get is not symmetric with \c std::time_put, so you cannot parse dates and times created with \c std::time_put .
       (This issue is addressed in C++0x and some STL implementation like the Apache standard C++ library.)
-   \c std::messages does not provide support for plural forms, making it impossible to correctly localize such simple strings as
       "There are X files in the directory".

Also, many features are not really supported by \c std::locale at all: timezones (as mentioned above), text boundary analysis, number
spelling, and many others. So it is clear that the standard C++ locales are problematic for real-world applications.

\subsection why_icu Why use an ICU wrapper instead of ICU?

ICU is a very good localization library, but it has several serious flaws:

- It is absolutely unfriendly to C++ developers. It ignores popular C++ idioms (the STL, RTTI, exceptions, etc), instead
mostly mimicking the Java API.
- It provides support for only one kind of string, UTF-16, when some users may want other Unicode encodings.
For example, for XML or HTML processing UTF-8 is much more convenient and UTF-32 easier to use. Also there is no support for
"narrow" encodings that are still very popular, such as the ISO-8859 encodings.

For example: Boost.Locale provides direct integration with \c iostream allowing a more natural way of data formatting. For example:

\code
    cout << "You have "<<as::currency << 134.45 << " in your account as of "<<as::datetime << std::time(0) << endl;
\endcode

\subsection why_icu_wrapper Why an ICU wrapper and not an implementation-from-scratch?

ICU is one of the best localization/Unicode libraries available. It consists of about half a million lines of well-tested,
production-proven source code that today provides state-of-the art localization tools.

Reimplementing of even a small part of ICU's abilities is an infeasible project which would require many man-years. So the
question is not whether we need to reimplement the Unicode and localization algorithms from scratch, but "Do we need a good
localization library in Boost?"

Thus Boost.Locale wraps ICU with a modern C++ interface, allowing future reimplementation of parts with better alternatives,
but bringing localization support to Boost today and not in the not-so-near-if-at-all future.


\subsection why_icu_api_is_hidden Why is the ICU API not exposed to the user?

Yes, the entire ICU API is hidden behind opaque pointers and users have no access to it. This is done for several reasons:

- At some point, better localization tools may be accepted by future upcoming C++ standards, so they may not use ICU directly.
- At some point, it should be possible to switch the underlying localization engine to something else, maybe the native operating
system API or some other toolkit such as GLib or Qt that provides similar functionality.
- Not all localization is done within ICU. For example, message formatting uses GNU Gettext message catalogs. In the future more
functionality may be reimplemented directly in the Boost.Locale library.
- Boost.Locale was designed with ABI stability in mind, as this library is being developed not only for Boost but also
for the needs of the <a href="http://cppcms.sourceforge.net/">CppCMS C++ Web framework</a>.


\subsection why_gnu_gettext Why use GNU Gettext catalogs for message formatting?

There are many available localization formats. The most popular so far are OASIS XLIFF, GNU gettext po/mo files, POSIX catalogs, Qt ts/tm files, Java properties, and Windows resources. However, the last three are useful only in their specific areas, and POSIX catalogs are too simple and limited, so there are only two reasonable options:

-# Standard localization format OASIS XLIFF.
-# GNU Gettext binary catalogs.

The first one generally seems like a more correct localization solution, but it requires XML parsing for loading documents,
it is very complicated format, and even ICU requires preliminary compilation of it into ICU resource bundles.

On the other hand:

- GNU Gettext binary catalogs have a very simple, robust and yet very useful file format.
- It is at present the most popular and de-facto standard localization format (at least in the Open Source world).
- It has very simple and powerful support for plural forms.
- It uses the original English text as the key, making the process of internationalization much easier because at least
one basic translation is always available.
- There are many tools for editing and managing gettext catalogs, such as Poedit, kbabel etc.

So, even though the GNU Gettext mo catalog format is not an officially approved file format:

- It is a de-facto standard and the most popular one.
- Its implementation is much easier and does not require XML parsing and validation.


\note Boost.Locale does not use any of the GNU Gettext code, it just reimplements the tool for reading and using mo-files,
eliminating the biggest GNU Gettext flaw at present -- thread safety when using multiple locales.

\subsection why_plain_number Why is a plain number used for the representation of a date-time, instead of a Boost.DateTime date or Boost.DateTime ptime?

There are several reasons:

-#  A Gregorian Date by definition can't be used to represent locale-independent dates, because not all
    calendars are Gregorian.
-#  \c ptime -- definitely could be used, but it has several problems:
    .   
    -   It is created in GMT or Local time clock, when `time()` gives a representation that is independent of time zones
        (usually GMT time), and only later should it be represented in a time zone that the user requests.
        \n
        The timezone is not a property of time itself, but it is rather a property of time formatting.
        .
    -   \c ptime already defines \c operator<< and \c operator>> for time formatting and parsing.
    -   The existing facets for \c ptime formatting and parsing were not designed in a way that the user can override.
        The major formatting and parsing functions are not virtual. This makes it impossible to reimplement the formatting and
        parsing functions of \c ptime unless the developers of the Boost.DateTime library decide to change them.
        \n
        Also, the facets of \c ptime are not "correctly" designed in terms of division of formatting information and 
        locale information. Formatting information should be stored within \c std::ios_base and information about
        locale-specific formatting should be stored in the facet itself.
        \n
        The user of the library should not have to create new facets to change simple formatting information like "display only
        the date" or "display both date and time."

Thus, at this point, \c ptime is not supported for formatting localized dates and times.

\subsection why_posix_names Why are POSIX locale names used and not something like the BCP-47 IETF language tag?

There are several reasons:

- POSIX locale names have a very important feature: character encoding. When you specify for example fr-FR, you
do not actually know how the text should be encoded -- UTF-8, ISO-8859-1, ISO-8859-15 or maybe Windows-1252.
This may vary between different operating systems and is depend on the current installation. So it is critical
to provide all the required information.
- ICU fully understands POSIX locales and knows how to treat them correctly.
- They are native locale names for most operating system APIs (with the exception of Windows)

\subsection why_linear_chunks Why most parts of Boost.Locale work only on linear/contiguous chunks of text

There are two reasons:

- Boost.Locale relies heavily on the third-party APIs like ICU, POSIX or Win32 API, all of them
  work only on linear chunks of text, so providing non-linear API would just hide the
  real situation and would not bring read performance advantage.
- In fact, all known libraries that work with Unicode: ICU, Qt, Glib, Win32 API, POSIX API 
  and others accept an input as single linear chunk of text and there is a good reason for this:
  \n
  -#  Most of supported operations on text like collation, case handling usually work on small
      chunks of text. For example: you probably would never want to compare two chapters of a book, but rather
      their titles.
  -#  We should remember that even very large texts require quite a small amount of memory, for example
      the entire book "War and Peace" takes only about 3MB of memory.
   \n

However:

-  There are API's that support stream processing. For example: character set conversion using
\c std::codecvt API works on streams of any size without problems.
-  When new API is introduced into Boost.Locale in future, such that it likely works
   on large chunks of text, will provide an interface for non-linear text handling.


\subsection why_abstract_api Why all Boost.Locale implementation is hidden behind abstract interfaces and does not use template metaprogramming?

There are several major reasons:

- This is how the C++'s \c std::locale class is build. Each feature is represented using a subclass of
  \c std::locale::facet that provides an abstract API for specific operations it works on, see \ref std_locales.
- This approach allows to switch underlying API without changing the actual application code even in run-time depending
  on performance and localization requirements.
- This approach reduces compilation times significantly. This is very important for library that may be
  used in almost every part of specific program.

\subsection why_no_special_character_type Why Boost.Locale does not provide char16_t/char32_t for non-C++0x platforms.

There are several reasons:

- C++0x defines \c char16_t and \c char32_t as distinct types, so substituting is with something like \c uint16_t or \c uint32_t
  would not work as for example writing \c uint16_t to \c uint32_t stream would write a number to stream.
- The C++ locales system would work only of standard facets like \c std::num_put are installed into the 
  existing instance of \c std::locale, however in the many standard C++ libraries these facets are specialized for each
  specific character that the standard library supports, so an attempt to create a new facet would
  fail as it is not specialized.
  
These are exactly the reasons why Boost.Locale fails with current limited C++0x characters support on GCC-4.5 (the second reason)
and MSVC-2010 (the first reason)

So basically it is impossible to use non-C++ characters with the C++'s locales framework.

The best and the most portable solution is to use the C++'s \c char type and UTF-8 encodings.

\section default_encoding_under_windows Default Encoding under Microsoft Windows

All modern operating systems use Unicode.

-   Unix operating system family use UTF-8 encoding by default.
-   Microsoft Windows had migrated to Wide/UTF-16 API.
    The narrow encodings had been deprecated and the native OS API became so called "Wide API"

As a result of radically different approaches, it is very hard to write portable Unicode aware applications.

Boost locale fully supports both narrow and wide API. The default character
encoding is assumed to be UTF-8 on Windows.

So if the default operating system Locale is "English_USA.1252" the default
locale for Boost.Locale on Windows would be "en_US.UTF-8".

When the created locale object is installed globally then any libraries
that use \c std::codecvt for conversion between narrow API and the native
wide API would handle UTF-8 correctly.

A good example of such library is Boost.Filesystem v3.

For example

\code
#include <boost/locale.hpp>
#include <boost/filesystem/path.hpp>
#include <boost/filesystem/fstream.hpp>

int main()
{
    // Create and install global locale
    std::locale::global(boost::locale::generator().generate(""));
    // Make boost.filesystem use it
    boost::filesystem::path::imbue(std::locale());
    // Now Works perfectly fine with UTF-8!
    boost::filesystem::ofstream hello("שלום.txt"); 
}

\endcode

However such behavior may broke existing software that assumes that the current
encoding is single byte encodings like code page 1252.

\ref boost::locale::generator class has a property \ref boost::locale::generator::use_ansi_encoding() "use_ansi_encoding()"
that allows to change the behavior to legacy one and select an ANSI code page as
default system encoding.

So, when the current locale is "English_USA.1252" and the \c use_ansi_encoding is turned on
then the default locale would be "en_US.windows-1252"

\note \c winapi backend does not support ANSI encodings, thus UTF-8 encoding is always used for narrow characters.

\section running_examples_under_windows Running Examples under Microsoft Windows

All of the examples that come with Boost.Locale are designed for UTF-8 and it is
the default encoding used by Boost.Locale.

However, the default narrow encoding under Microsoft Windows is not UTF-8 and 
the output of the applications would not be displayed correctly in the console.

So in order to use UTF-8 encoding under the Windows console and see the output correctly, do the following:

-# Open a \c cmd window
-# Change the default font to a TrueType font: go to properties-\>font (right click on title-bar-\>properties-\>font) and
change the font to a TrueType font like Lucida Console
-# Change the default codepage to 65001 (UTF-8) by running <tt>chcp 65001</tt>

Now all of the examples should display UTF-8 characters correctly (if the font supports them).

<b>Note for Visual Studio users:</b> Microsoft Visual Studio assumes that all source files are encoded using an "ANSI" codepage
like 1252. However all examples use UTF-8 encoding by default, so wide character examples would
not work under MSVC as-is. In order to force it to treat source files as UTF-8 you need to
convert the files to UTF-8 with BOM, which can be done easily by re-saving them from Notepad,
which adds a BOM to UTF-8 files by default.


\section glossary Glossary

-   <b>Basic Multilingual Plane (BMP)</b> -- a part of the <i>Universal Character Set</i> with code points in tje range U-0000--U-FFFF.
    The most commonly used UCS characters lay in this plane, including all Western, Cyrillic, Hebrew, Thai, Arabic and CJK encodings.
    However there are many characters that lay outside the BMP and they are absolutely required for correct support of East Asian languages.
-   \b Code \b Point -- a unique number that represents a "character" in the Universal Character Set. Code points lay in the range of
    0-0x10FFFF, and are usually displayed as U+XXXX or U+XXXXXX, where X represents a hexadecimal digit.
-   \b Collation -- a sorting order for text, usually alphabetical. It can differ between languages and countries, even for the same
    characters.
-   \b Encoding -- a representation of a character set. Some encodings are capable of representing the full UCS range, like UTF-8, and
    others can only represent a subset of it -- ISO-8859-8 represents only a small subset of about 250 characters of the UCS.
    \n
    Non-Unicode encodings are still very popular, for example the Latin-1 (or ISO-8859-1) encoding covers most of the characters for
    Western European languages and significantly simplifies the processing of text for applications designed to handle only such languages.
    \n
    For Boost.Locale you should provide an eight-bit (\c std::sting) encoding as part of the locale name, like \c en_US.UTF-8 or
    \c he_IL.cp1255 . \c UTF-8 is recommended.
-   \b Facet -- or \c std::locale::facet -- a base class that every object that describes a specific locale is derived from. Facets can be
    added to a locale to provide additional culture information.
-   \b Formatting -- representation of various values according to locale preferences. For example, a number 1234.5 (C representation)
    should be displayed as 1,234.5 in the US locale and 1.234,5 in the Russian locale. The date November 1st, 2005 would be represented as
    11/01/2005 in the United States, and 01.11.2005 in Russia. This is an important part of localization.
    \n 
    For example: does "You have to bring 134,230 kg of rice on 04/01/2010" means "134 tons of rice on the first of April" or "134 kg 230 g
    of rice on January 4th"? That is quite different.
-   \b Gettext -- The GNU localization library used for message formatting. Today it is the de-facto standard localization library in the
    Open Source world. Boost.Locale message formatting is entirely built on Gettext message catalogs.
-   \b Locale -- a set of parameters that define specific preferences for users in different cultures. It is generally defined by language,
    country, variants, and encoding, and provides information like: collation order, date-time formatting, message formatting, number
    formatting and many others. In C++, locale information is represented by the \c std::locale class.
-   \b Message \b Formatting -- the representation of user interface strings in the user's language. The process of translation of UI
    strings is generally done using some dictionary provided by the program's translator.
-   \b Message \b Domain -- in \a gettext terms, the keyword that represents a message catalog. This is usually an application name. When
    \a gettext and Boost.Locale search for a specific message catalog, they search in the specified path for a file named after the domain.
-   \b Normalization -- Unicode normalization is the process of converting strings to a standard form, suitable for text processing and
    comparison. For example, character "ü" can be represented by a single code point or a combination of the character "u" and the
    diaeresis "¨". Normalization is an important part of Unicode text processing.
    \n
    Normalization is not locale-dependent, but because it is an important part of Unicode processing, it is included in the Boost.Locale
    library.
-   \b UCS-2 -- a fixed-width Unicode encoding, capable of representing only code points in the <i>Basic Multilingual Plane (BMP)</i>.
    It is a legacy encoding and is not recommended for use.
-   \b Unicode -- the industry standard that defines the representation and manipulation of text suitable for most languages and countries. 
    It should not be confused with the <i>Universal Character Set</i>, it is a much larger standard that also defines algorithms like
    bidirectional display order, Arabic shaping, etc.
-   <b>Universal Character Set (UCS)</b> -- an international standard that defines a set of characters for many scripts and their
    \a code \a points.
-   \b UTF-8 -- a variable-width Unicode transformation format. Each UCS code point is represented as a sequence of between 1 and 4 octets
    that can be easily distinguished. It includes ASCII as a subset. It is the most popular Unicode encoding for web applications, data
    transfer and storage, and is the de-facto standard encoding for most POSIX operation systems.
-   \b UTF-16 -- a variable-width Unicode transformation format. Each UCS code point is represented as a sequence of one or two 16-bit words.
    It is a very popular encoding for platforms such as the Win32 API, Java, C#, Python, etc. However, it is frequently confused with the
    _UCS-2_ fixed-width encoding, which can only represent characters in the <i>Basic Multilingual Plane (BMP)</i>.
    \n
    This encoding is used for \c std::wstring under the Win32 platform, where <tt>sizeof(wchar_t)==2</tt>.
-   \b UTF-32/UCS-4 - a fixed-width Unicode transformation format, where each code point is represented as a single 32-bit word. It has
    the advantage of simple code point representation, but is wasteful in terms of memory usage. It is used for \c std::wstring encoding
    for most POSIX platforms, where <tt>sizeof(wchar_t)==4</tt>.

\section tested_compilers_and_paltforms Tested Compilers and Platforms

<table border="1" cellpadding="5" cellspacing="3">
<tr>
  <th>Platform</th><th>Compiler</th><th>Backends</th><th>ICU version</th><th>Notes</th>
</tr>
<tr>
  <td>Linux 2.6 x86_64</td><td>GCC-4.3</td><td>icu/posix/std</td><td>3.8, 4.4, 4.6</td><td>-</td>
</tr>
<tr>
  <td>Linux 2.6 x86</td><td>GCC-4.1</td><td>icu/posix/std</td><td>3.6</td><td>(not tested recently)</td>
</tr>
<tr>
  <td>Linux 2.6 x86_64</td><td>GCC-4.4</td><td>icu/posix/std</td><td>4.2</td><td>-</td>
</tr>
<tr>
  <td>Linux 2.6 x86_64</td><td>GCC-4.5/C++0x</td><td>icu/posix/std</td><td>3.8</td><td>-</td>
</tr>
<tr>
  <td>Linux 2.6 x86_64</td><td>GCC-4.5/C++0x with char16_t/char32_t</td><td>icu</td><td>3.8</td>
  <td>
	Some charXX_t faults in formatting<br>
	std backend can't be build<br>
	Standard library issues
  </td>
</tr>
<tr>
  <td>Linux 2.6 x86_64</td><td>Intel 11.0</td><td>icu/posix/std</td><td>3.8</td><td>-</td>
</tr>
<tr>
  <td>Windows 7 32bit</td><td>MSVC 2010</td><td>icu/winapi/std</td><td>4.6</td><td>-</td>
</tr>
<tr>
  <td>Windows 7 32bit</td><td>MSVC 2010/C++0x with char16_t/char32_t</td><td>icu/winapi/std</td><td>4.6</td>
  <td>
  Multiple test faults, because char16_t/char32_t are not
  defined as distinct types as required by C++ standard.
  </td>
</tr>
<tr>
  <td>Windows XP 32bit</td><td>MSVC 2008</td><td>icu/winapi/std</td><td>4.2</td><td>-</td>
</tr>
<tr>
  <td>Windows XP 32bit</td><td>MinGW/GCC 4.5</td><td>icu/winapi/std</td><td>4.2</td><td>-</td>
</tr>
<tr>
  <td>Cygwin 1.7</td><td>GCC 4.3</td><td>icu/winapi/std</td><td>3.8</td><td>-</td>
</tr>
<tr>
  <td>Mac OS X 10.6.4</td><td>GCC-4.2</td><td>icu/posix/std</td><td>4.4</td><td>-</td>
</tr>
<tr>
  <td>FreeBSD 8.0</td><td>GCC-4.2.1</td><td>icu/std</td><td>3.8</td><td>-</td>
</tr>
<tr>
  <td>OpenSolaris/SunOS 5.11</td><td>GCC-3.4</td><td>icu/std</td><td>4.2</td><td>iconv is disabled</td>
</tr>
<tr>
  <td>OpenSolaris/SunOS 5.11</td><td>SunCC 5.10/STLport4</td><td>icu</td><td>4.2</td>
  <td>
    Some faults in collation, STLport issue<br/>
    iconv is disabled<br/>
    Boost-1.46.x requires patch for Boost.Thread, can be found in <tt>libs/locale/build</tt>
  </td>
</tr>
</table>

\section status_of_cpp0x_characters_support Status of C++0x char16_t/char32_t support

The support of C++0x \c char16_t and \c char32_t is experimental, mostly does not work and not
indented to be used in production with current latest compilers: GCC-4.5, MSVC10 till major
compiler's flaws would be fixed.

\subsection status_of_cpp0x_characters_support_gnu GNU GCC 4.5/C++0x Status

GNU C++ compiler provides decent support of C++0x characters however:

-# 	Standard library does not install any std::locale::facets for this support so any attempt
    to format numbers using \c char16_t or \c char32_t streams would just fail.
-#	Standard library misses specialization for required \c char16_t/char32_t locale facets,
	so "std" backends is not build-able as essential symbols missing, also \c codecvt facet
	can't be created as well.

\subsection status_of_cpp0x_characters_support_msvc Visual Studio 2010 (MSVC10)/C++0x Status

MSVC provides all required facets however:

-# 	Standard library does not provide installations of std::locale::id for these facets
	in DLL so it is not usable with \c /MD, \c /MDd compiler flags and requires static link of the runtime
	library.
-#	\c char16_t and \c char32_t are not distinct types but rather aliases of unsigned short and unsigned
	types which contradicts to C++0x requirements making it impossible to write \c char16_t/char32_t to stream
	and causing multiple faults.

\section special_thanks Special Thanks 

(in alphabetical order)

-   Chad Nelson - for volunteering to manage the formal review and for the great language corrections 
    for this tutorial.
-   Vladimir Prus - for development of Boost.Build support for Boost.Locale.

\section copyright Copyrights


  Copyright &copy; 2009-2011 Artyom Beilis (Tonkikh)

  Distributed under the Boost Software License, Version 1.0. (See
  accompanying file LICENSE_1_0.txt or copy at
  http://www.boost.org/LICENSE_1_0.txt)

*/
