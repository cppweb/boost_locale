// vim: tabstop=4 expandtab shiftwidth=4 softtabstop=4 filetype=cpp.doxygen
/*!
\page appendix Appendix

\section appendix_toc Table of Contents 

- \ref rationale
- \ref default_encoding_under_windows
- \ref running_examples_under_windows 
- \ref glossary
- \ref tested_compilers_and_paltforms 
- \ref status_of_cpp0x_characters_support
- \ref special_thanks
- \ref copyright

\section rationale Design Rationale 

- \ref rationale_why
- \ref why_icu
- \ref why_icu_wrapper 
- \ref why_icu_api_is_hidden
- \ref why_gnu_gettext 
- \ref why_posix_names
- \ref why_linear_chunks
- \ref why_abstract_api
- \ref why_no_special_character_type

\subsection rationale_why Why is it needed?

Why do we need a localization library, when standard C++ facets (should) provide most of the required functionality:

- Case conversion is done using the \c std::ctype facet
- Collation is supported by \c std::collate and has nice integration with \c std::locale
- There are \c std::num_put , \c std::num_get , \c std::money_put , \c std::money_get , \c std::time_put and \c std::time_get for numbers,
    time, and currency formatting and parsing.
- There is a \c std::messages class that supports localized message formatting.

So why do we need such library if we have all the functionality within the standard library?

Almost every(!) facet has design flaws:

-  \c std::collate supports only one level of collation, not allowing you to choose whether case- or accent-sensitive comparisons
    should be performed.

-  \c std::ctype, which is responsible for case conversion, assumes that all conversions can be done on a per-character basis. This is
    probably correct for many languages but it isn't correct in general.
    .
    -# Case conversion may change a string's length. For example, the German word "grüßen" should be converted to "GRÜSSEN" in upper
    case: the letter "ß" should be converted to "SS", but the \c toupper function works on a single-character basis.
    -# Case conversion is context-sensitive. For example, the Greek word "ὈΔΥΣΣΕΎΣ" should be converted to "ὀδυσσεύς", where the Greek letter
    "Σ" is converted to "σ" or to "ς", depending on its position in the word.
    -# Case conversion cannot assume that a character is a single code point, which is incorrect for both the UTF-8 and UTF-16 encodings,
       where individual code-points are represented by up to 4 \c char 's or two \c wchar_t 's on the Windows platform. This makes
       \c std::ctype totally useless with these encodings.
-   \c std::numpunct and \c std::moneypunct do not specify the code points for digit representation at all,
    so they cannot format numbers with the digits used under Arabic locales. For example,
    the number "103" is expected to be displayed as "١٠٣" in the \c ar_EG locale.
    \n
    \c std::numpunct and \c std::moneypunct assume that the thousands separator is a single character. This is untrue
    for the UTF-8 encoding where only Unicode 0-0x7F range can be represented as a single character. As a result, localized numbers can't be
    represented correctly under locales that use the Unicode "EN SPACE" character for the thousands separator, such as Russian.
    \n
    This actually causes real problems under GCC and SunStudio compilers, where formatting numbers under a Russian locale creates invalid 
    UTF-8 sequences.
-   \c std::time_put and \c std::time_get have several flaws:
    -# They assume that the calendar is always Gregorian, by using \c std::tm for time representation, ignoring the fact that in many
       countries dates may be displayed using different calendars.
    -# They always use a global time zone, not allowing specification of the time zone for formatting. The standard \c std::tm doesn't
       even include a timezone field at all.
    -# \c std::time_get is not symmetric with \c std::time_put, so you cannot parse dates and times created with \c std::time_put .
       (This issue is addressed in C++0x and some STL implementation like the Apache standard C++ library.)
-   \c std::messages does not provide support for plural forms, making it impossible to correctly localize such simple strings as
       "There are X files in the directory".

Also, many features are not really supported by \c std::locale at all: timezones (as mentioned above), text boundary analysis, number
spelling, and many others. So it is clear that the standard C++ locales are problematic for real-world applications.

\subsection why_icu Why use an ICU wrapper instead of ICU?

ICU is a very good localization library, but it has several serious flaws:

- It is absolutely unfriendly to C++ developers. It ignores popular C++ idioms (the STL, RTTI, exceptions, etc), instead
mostly mimicking the Java API.
- It provides support for only one kind of string, UTF-16, when some users may want other Unicode encodings.
For example, for XML or HTML processing UTF-8 is much more convenient and UTF-32 easier to use. Also there is no support for
"narrow" encodings that are still very popular, such as the ISO-8859 encodings.

For example: Boost.Locale provides direct integration with \c iostream allowing a more natural way of data formatting. For example:

\code
    cout << "You have "<<as::currency << 134.45 << " in your account as of "<<as::datetime << std::time(0) << endl;
\endcode

\subsection why_icu_wrapper Why an ICU wrapper and not an implementation-from-scratch?

ICU is one of the best localization/Unicode libraries available. It consists of about half a million lines of well-tested,
production-proven source code that today provides state-of-the art localization tools.

Reimplementing of even a small part of ICU's abilities is an infeasible project which would require many man-years. So the
question is not whether we need to reimplement the Unicode and localization algorithms from scratch, but "Do we need a good
localization library in Boost?"

Thus Boost.Locale wraps ICU with a modern C++ interface, allowing future reimplementation of parts with better alternatives,
but bringing localization support to Boost today and not in the not-so-near-if-at-all future.


\subsection why_icu_api_is_hidden Why is the ICU API not exposed to the user?

Yes, the entire ICU API is hidden behind opaque pointers and users have no access to it. This is done for several reasons:

- At some point, better localization tools may be accepted by future upcoming C++ standards, so they may not use ICU directly.
- At some point, it should be possible to switch the underlying localization engine to something else, maybe the native operating
system API or some other toolkit such as GLib or Qt that provides similar functionality.
- Not all localization is done within ICU. For example, message formatting uses GNU Gettext message catalogs. In the future more
functionality may be reimplemented directly in the Boost.Locale library.
- Boost.Locale was designed with ABI stability in mind, as this library is being developed not only for Boost but also
for the needs of the <a href="http://cppcms.sourceforge.net/">CppCMS C++ Web framework</a>.


\subsection why_gnu_gettext Why use GNU Gettext catalogs for message formatting?

There are many available localization formats. The most popular so far are OASIS XLIFF, GNU gettext po/mo files, POSIX catalogs, Qt ts/tm files, Java properties, and Windows resources. However, the last three are useful only in their specific areas, and POSIX catalogs are too simple and limited, so there are only two reasonable options:

-# Standard localization format OASIS XLIFF.
-# GNU Gettext binary catalogs.

The first one generally seems like a more correct localization solution, but it requires XML parsing for loading documents,
it is very complicated format, and even ICU requires preliminary compilation of it into ICU resource bundles.

On the other hand:

- GNU Gettext binary catalogs have a very simple, robust and yet very useful file format.
- It is at present the most popular and de-facto standard localization format (at least in the Open Source world).
- It has very simple and powerful support for plural forms.
- It uses the original English text as the key, making the process of internationalization much easier because at least
one basic translation is always available.
- There are many tools for editing and managing gettext catalogs, such as Poedit, kbabel etc.

So, even though the GNU Gettext mo catalog format is not an officially approved file format:

- It is a de-facto standard and the most popular one.
- Its implementation is much easier and does not require XML parsing and validation.


\note Boost.Locale does not use any of the GNU Gettext code, it just reimplements the tool for reading and using mo-files,
eliminating the biggest GNU Gettext flaw at present -- thread safety when using multiple locales.

\subsection why_plain_number Why is a plain number used for the representation of a date-time, instead of a Boost.DateTime date or Boost.DateTime ptime?

There are several reasons:

-#  A Gregorian Date by definition can't be used to represent locale-independent dates, because not all
    calendars are Gregorian.
-#  \c ptime -- definitely could be used, but it has several problems:
    .   
    -   It is created in GMT or Local time clock, when `time()` gives a representation that is independent of time zones
        (usually GMT time), and only later should it be represented in a time zone that the user requests.
        \n
        The timezone is not a property of time itself, but it is rather a property of time formatting.
        .
    -   \c ptime already defines \c operator<< and \c operator>> for time formatting and parsing.
    -   The existing facets for \c ptime formatting and parsing were not designed in a way that the user can override.
        The major formatting and parsing functions are not virtual. This makes it impossible to reimplement the formatting and
        parsing functions of \c ptime unless the developers of the Boost.DateTime library decide to change them.
        \n
        Also, the facets of \c ptime are not "correctly" designed in terms of division of formatting information and 
        locale information. Formatting information should be stored within \c std::ios_base and information about
        locale-specific formatting should be stored in the facet itself.
        \n
        The user of the library should not have to create new facets to change simple formatting information like "display only
        the date" or "display both date and time."

Thus, at this point, \c ptime is not supported for formatting localized dates and times.

\subsection why_posix_names Why are POSIX locale names used and not something like the BCP-47 IETF language tag?

There are several reasons:

- POSIX locale names have a very important feature: character encoding. When you specify for example fr-FR, you
do not actually know how the text should be encoded -- UTF-8, ISO-8859-1, ISO-8859-15 or maybe Windows-1252.
This may vary between different operating systems and is depend on the current installation. So it is critical
to provide all the required information.
- ICU fully understands POSIX locales and knows how to treat them correctly.
- They are native locale names for most operating system APIs (with the exception of Windows)

\subsection why_linear_chunks Why most parts of Boost.Locale work only on linear/contiguous chunks of text

There are two reasons:

- Boost.Locale relies heavily on the third-party APIs like ICU, POSIX or Win32 API, all of them
  work only on linear chunks of text, so providing non-linear API would just hide the
  real situation and would not bring read performance advantage.
- In fact, all known libraries that work with Unicode: ICU, Qt, Glib, Win32 API, POSIX API 
  and others accept an input as single linear chunk of text and there is a good reason for this:
  \n
  -#  Most of supported operations on text like collation, case handling usually work on small
      chunks of text. For example: you probably would never want to compare two chapters of a book, but rather
      their titles.
  -#  We should remember that even very large texts require quite a small amount of memory, for example
      the entire book "War and Peace" takes only about 3MB of memory.
   \n

However:

-  There are API's that support stream processing. For example: character set conversion using
\c std::codecvt API works on streams of any size without problems.
-  When new API is introduced into Boost.Locale in future, such that it likely works
   on large chunks of text, will provide an interface for non-linear text handling.


\subsection why_abstract_api Why all Boost.Locale implementation is hidden behind abstract interfaces and does not use template metaprogramming?

There are several major reasons:

- This is how the C++'s \c std::locale class is build. Each feature is represented using a subclass of
  \c std::locale::facet that provides an abstract API for specific operations it works on, see \ref std_locales.
- This approach allows to switch underlying API without changing the actual application code even in run-time depending
  on performance and localization requirements.
- This approach reduces compilation times significantly. This is very important for library that may be
  used in almost every part of specific program.

\subsection why_no_special_character_type Why Boost.Locale does not provide char16_t/char32_t for non-C++0x platforms.

There are several reasons:

- C++0x defines \c char16_t and \c char32_t as distinct types, so substituting is with something like \c uint16_t or \c uint32_t
  would not work as for example writing \c uint16_t to \c uint32_t stream would write a number to stream.
- The C++ locales system would work only of standard facets like \c std::num_put are installed into the 
  existing instance of \c std::locale, however in the many standard C++ libraries these facets are specialized for each
  specific character that the standard library supports, so an attempt to create a new facet would
  fail as it is not specialized.
  
These are exactly the reasons why Boost.Locale fails with current limited C++0x characters support on GCC-4.5 (the second reason)
and MSVC-2010 (the first reason)

So basically it is impossible to use non-C++ characters with the C++'s locales framework.

The best and the most portable solution is to use the C++'s \c char type and UTF-8 encodings.

\section default_encoding_under_windows Default Encoding under Microsoft Windows

All modern operating systems use Unicode.

-   Unix operating system family use UTF-8 encoding by default.
-   Microsoft Windows had migrated to Wide/UTF-16 API.
    The narrow encodings had been deprecated and the native OS API became so called "Wide API"

As a result of radically different approaches, it is very hard to write portable Unicode aware applications.

Boost locale fully supports both narrow and wide API. The default character
encoding is assumed to be UTF-8 on Windows.

So if the default operating system Locale is "English_USA.1252" the default
locale for Boost.Locale on Windows would be "en_US.UTF-8".

When the created locale object is installed globally then any libraries
that use \c std::codecvt for conversion between narrow API and the native
wide API would handle UTF-8 correctly.

A good example of such library is Boost.Filesystem v3.

For example

\code
#include <boost/locale.hpp>
#include <boost/filesystem/path.hpp>
#include <boost/filesystem/fstream.hpp>

int main()
{
    // Create and install global locale
    std::locale::global(boost::locale::generator().generate(""));
    // Make boost.filesystem use it
    boost::filesystem::path::imbue(std::locale());
    // Now Works perfectly fine with UTF-8!
    boost::filesystem::ofstream hello("שלום.txt"); 
}

\endcode

However such behavior may broke existing software that assumes that the current
encoding is single byte encodings like code page 1252.

\ref boost::locale::generator class has a property \ref boost::locale::generator::use_ansi_encoding() "use_ansi_encoding()"
that allows to change the behavior to legacy one and select an ANSI code page as
default system encoding.

So, when the current locale is "English_USA.1252" and the \c use_ansi_encoding is turned on
then the default locale would be "en_US.windows-1252"

\note \c winapi backend does not support ANSI encodings, thus UTF-8 encoding is always used for narrow characters.

\section running_examples_under_windows Running Examples under Microsoft Windows

All of the examples that come with Boost.Locale are designed for UTF-8 and it is
the default encoding used by Boost.Locale.

However, the default narrow encoding under Microsoft Windows is not UTF-8 and 
the output of the applications would not be displayed correctly in the console.

So in order to use UTF-8 encoding under the Windows console and see the output correctly, do the following:

-# Open a \c cmd window
-# Change the default font to a TrueType font: go to properties-\>font (right click on title-bar-\>properties-\>font) and
change the font to a TrueType font like Lucida Console
-# Change the default codepage to 65001 (UTF-8) by running <tt>chcp 65001</tt>

Now all of the examples should display UTF-8 characters correctly (if the font supports them).

<b>Note for Visual Studio users:</b> Microsoft Visual Studio assumes that all source files are encoded using an "ANSI" codepage
like 1252. However all examples use UTF-8 encoding by default, so wide character examples would
not work under MSVC as-is. In order to force it to treat source files as UTF-8 you need to
convert the files to UTF-8 with BOM, which can be done easily by re-saving them from Notepad,
which adds a BOM to UTF-8 files by default.


\section glossary Glossary

-   <b>Basic Multilingual Plane (BMP)</b> -- a part of the <i>Universal Character Set</i> with code points in tje range U-0000--U-FFFF.
    The most commonly used UCS characters lay in this plane, including all Western, Cyrillic, Hebrew, Thai, Arabic and CJK encodings.
    However there are many characters that lay outside the BMP and they are absolutely required for correct support of East Asian languages.
-   \b Code \b Point -- a unique number that represents a "character" in the Universal Character Set. Code points lay in the range of
    0-0x10FFFF, and are usually displayed as U+XXXX or U+XXXXXX, where X represents a hexadecimal digit.
-   \b Collation -- a sorting order for text, usually alphabetical. It can differ between languages and countries, even for the same
    characters.
-   \b Encoding -- a representation of a character set. Some encodings are capable of representing the full UCS range, like UTF-8, and
    others can only represent a subset of it -- ISO-8859-8 represents only a small subset of about 250 characters of the UCS.
    \n
    Non-Unicode encodings are still very popular, for example the Latin-1 (or ISO-8859-1) encoding covers most of the characters for
    Western European languages and significantly simplifies the processing of text for applications designed to handle only such languages.
    \n
    For Boost.Locale you should provide an eight-bit (\c std::sting) encoding as part of the locale name, like \c en_US.UTF-8 or
    \c he_IL.cp1255 . \c UTF-8 is recommended.
-   \b Facet -- or \c std::locale::facet -- a base class that every object that describes a specific locale is derived from. Facets can be
    added to a locale to provide additional culture information.
-   \b Formatting -- representation of various values according to locale preferences. For example, a number 1234.5 (C representation)
    should be displayed as 1,234.5 in the US locale and 1.234,5 in the Russian locale. The date November 1st, 2005 would be represented as
    11/01/2005 in the United States, and 01.11.2005 in Russia. This is an important part of localization.
    \n 
    For example: does "You have to bring 134,230 kg of rice on 04/01/2010" means "134 tons of rice on the first of April" or "134 kg 230 g
    of rice on January 4th"? That is quite different.
-   \b Gettext -- The GNU localization library used for message formatting. Today it is the de-facto standard localization library in the
    Open Source world. Boost.Locale message formatting is entirely built on Gettext message catalogs.
-   \b Locale -- a set of parameters that define specific preferences for users in different cultures. It is generally defined by language,
    country, variants, and encoding, and provides information like: collation order, date-time formatting, message formatting, number
    formatting and many others. In C++, locale information is represented by the \c std::locale class.
-   \b Message \b Formatting -- the representation of user interface strings in the user's language. The process of translation of UI
    strings is generally done using some dictionary provided by the program's translator.
-   \b Message \b Domain -- in \a gettext terms, the keyword that represents a message catalog. This is usually an application name. When
    \a gettext and Boost.Locale search for a specific message catalog, they search in the specified path for a file named after the domain.
-   \b Normalization -- Unicode normalization is the process of converting strings to a standard form, suitable for text processing and
    comparison. For example, character "ü" can be represented by a single code point or a combination of the character "u" and the
    diaeresis "¨". Normalization is an important part of Unicode text processing.
    \n
    Normalization is not locale-dependent, but because it is an important part of Unicode processing, it is included in the Boost.Locale
    library.
-   \b UCS-2 -- a fixed-width Unicode encoding, capable of representing only code points in the <i>Basic Multilingual Plane (BMP)</i>.
    It is a legacy encoding and is not recommended for use.
-   \b Unicode -- the industry standard that defines the representation and manipulation of text suitable for most languages and countries. 
    It should not be confused with the <i>Universal Character Set</i>, it is a much larger standard that also defines algorithms like
    bidirectional display order, Arabic shaping, etc.
-   <b>Universal Character Set (UCS)</b> -- an international standard that defines a set of characters for many scripts and their
    \a code \a points.
-   \b UTF-8 -- a variable-width Unicode transformation format. Each UCS code point is represented as a sequence of between 1 and 4 octets
    that can be easily distinguished. It includes ASCII as a subset. It is the most popular Unicode encoding for web applications, data
    transfer and storage, and is the de-facto standard encoding for most POSIX operation systems.
-   \b UTF-16 -- a variable-width Unicode transformation format. Each UCS code point is represented as a sequence of one or two 16-bit words.
    It is a very popular encoding for platforms such as the Win32 API, Java, C#, Python, etc. However, it is frequently confused with the
    _UCS-2_ fixed-width encoding, which can only represent characters in the <i>Basic Multilingual Plane (BMP)</i>.
    \n
    This encoding is used for \c std::wstring under the Win32 platform, where <tt>sizeof(wchar_t)==2</tt>.
-   \b UTF-32/UCS-4 - a fixed-width Unicode transformation format, where each code point is represented as a single 32-bit word. It has
    the advantage of simple code point representation, but is wasteful in terms of memory usage. It is used for \c std::wstring encoding
    for most POSIX platforms, where <tt>sizeof(wchar_t)==4</tt>.

\section tested_compilers_and_paltforms Tested Compilers and Platforms

<table border="1" cellpadding="5" cellspacing="3">
<tr>
  <th>Platform</th><th>Compiler</th><th>Backends</th><th>ICU version</th><th>Notes</th>
</tr>
<tr>
  <td>Linux 2.6 x86_64</td><td>GCC-4.3</td><td>icu/posix/std</td><td>3.8, 4.4, 4.6</td><td>-</td>
</tr>
<tr>
  <td>Linux 2.6 x86</td><td>GCC-4.1</td><td>icu/posix/std</td><td>3.6</td><td>(not tested recently)</td>
</tr>
<tr>
  <td>Linux 2.6 x86_64</td><td>GCC-4.4</td><td>icu/posix/std</td><td>4.2</td><td>-</td>
</tr>
<tr>
  <td>Linux 2.6 x86_64</td><td>GCC-4.5/C++0x</td><td>icu/posix/std</td><td>3.8</td><td>-</td>
</tr>
<tr>
  <td>Linux 2.6 x86_64</td><td>GCC-4.6</td><td>icu/posix/std</td><td>4.2, 4.6</td><td>-</td>
</tr>
<tr>
  <td>Linux 2.6 x86_64</td><td>GCC-4.6/C++0x</td><td>icu/posix/std</td><td>4.2, 4.6</td><td>-</td>
</tr>
<tr>
  <td>Linux 2.6 x86_64</td><td>GCC-4.5/C++0x with char16_t/char32_t</td><td>icu</td><td>3.8</td>
  <td>
	Some charXX_t faults in formatting<br>
	std backend can't be build<br>
	Standard library issues
  </td>
</tr>
<tr>
  <td>Linux 2.6 x86_64</td><td>Intel 11.0</td><td>icu/posix/std</td><td>3.8</td><td>-</td>
</tr>
<tr>
  <td>Windows 7 32bit</td><td>MSVC 2010</td><td>icu/winapi/std</td><td>4.6</td><td>-</td>
</tr>
<tr>
  <td>Windows 7 32bit</td><td>MSVC 2010/C++0x with char16_t/char32_t</td><td>icu/winapi/std</td><td>4.6</td>
  <td>
  Multiple test faults, because char16_t/char32_t are not
  defined as distinct types as required by C++ standard.
  </td>
</tr>
<tr>
  <td>Windows XP 32bit</td><td>MSVC 2008</td><td>icu/winapi/std</td><td>4.2</td><td>-</td>
</tr>
<tr>
  <td>Windows XP 32bit</td><td>MinGW/GCC 4.5</td><td>icu/winapi/std</td><td>4.2</td><td>-</td>
</tr>
<tr>
  <td>Cygwin 1.7</td><td>GCC 4.3</td><td>icu/winapi/std</td><td>3.8</td><td>-</td>
</tr>
<tr>
  <td>Mac OS X 10.6.4</td><td>GCC-4.2</td><td>icu/posix/std</td><td>4.4</td><td>-</td>
</tr>
<tr>
  <td>FreeBSD 8.0</td><td>GCC-4.2.1</td><td>icu/std</td><td>3.8</td><td>-</td>
</tr>
<tr>
  <td>OpenSolaris/SunOS 5.11</td><td>GCC-3.4</td><td>icu/std</td><td>4.2</td><td>iconv is disabled</td>
</tr>
<tr>
  <td>OpenSolaris/SunOS 5.11</td><td>SunCC 5.10/STLport4</td><td>icu</td><td>4.2</td>
  <td>
    Some faults in collation, STLport issue<br/>
    iconv is disabled<br/>
    Boost-1.46.x requires patch for Boost.Thread, can be found in <tt>libs/locale/build</tt>
  </td>
</tr>
</table>

\section status_of_cpp0x_characters_support Status of C++0x char16_t/char32_t support

The support of C++0x \c char16_t and \c char32_t is experimental, mostly does not work and not
indented to be used in production with current latest compilers: GCC-4.5, MSVC10 till major
compiler's flaws would be fixed.

\subsection status_of_cpp0x_characters_support_gnu GNU GCC 4.5/C++0x Status

GNU C++ compiler provides decent support of C++0x characters however:

-# 	Standard library does not install any std::locale::facets for this support so any attempt
    to format numbers using \c char16_t or \c char32_t streams would just fail.
-#	Standard library misses specialization for required \c char16_t/char32_t locale facets,
	so "std" backends is not build-able as essential symbols missing, also \c codecvt facet
	can't be created as well.

\subsection status_of_cpp0x_characters_support_msvc Visual Studio 2010 (MSVC10)/C++0x Status

MSVC provides all required facets however:

-# 	Standard library does not provide installations of std::locale::id for these facets
	in DLL so it is not usable with \c /MD, \c /MDd compiler flags and requires static link of the runtime
	library.
-#	\c char16_t and \c char32_t are not distinct types but rather aliases of unsigned short and unsigned
	types which contradicts to C++0x requirements making it impossible to write \c char16_t/char32_t to stream
	and causing multiple faults.

\section special_thanks Special Thanks 

(in alphabetical order)

-   Chad Nelson - for volunteering to manage the formal review and for the great language corrections 
    for this tutorial.
-   Vladimir Prus - for development of Boost.Build support for Boost.Locale.

\section copyright Copyrights


  Copyright &copy; 2009-2011 Artyom Beilis (Tonkikh)

  Distributed under the Boost Software License, Version 1.0. (See
  accompanying file LICENSE_1_0.txt or copy at
  http://www.boost.org/LICENSE_1_0.txt)

*/
